{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old functions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_with(df,\n",
    "                 codes,\n",
    "                 cols,\n",
    "                 pid='pid',\n",
    "                 sep=None,\n",
    "                 merge=True,\n",
    "                 first_date=None,\n",
    "                 last_date=None,\n",
    "                 group=False,\n",
    "                 _fix=True):\n",
    "    \"\"\"\n",
    "    Determine whether people have received a code\n",
    "\n",
    "    Args:\n",
    "        codes (list or dict): codes to mark for\n",
    "            codes to search for\n",
    "                - if list: each code will represent a column\n",
    "                - if dict: the codes in each item will be aggregated to one indicator\n",
    "            cols (str or list of str): Column(s) with the codes\n",
    "            pid (str): colum with the person identifier\n",
    "            first_date (str): use only codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "            last_date (str): only use codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "\n",
    "    Returns:\n",
    "        Series or Dataframe\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        fracture = persons_with(df=df, codes='S72*', cols='icdmain')\n",
    "        fracture = persons_with(df=df, codes={'frac':'S72*'}, cols='icdmain')\n",
    "\n",
    "    Todo:\n",
    "        - function may check if pid_index is unique, in which it does not have to aggregate\n",
    "        - this may apply in general? functions that work on event data may then also work on person level data\n",
    "        - allow user to input person level dataframe source?\n",
    "    \"\"\"\n",
    "    sub = df\n",
    "\n",
    "    if _fix:\n",
    "        df, cols = _to_df(df=df, cols=cols)\n",
    "        codes, cols, allcodes, sep = _fix_args(df=df, codes=codes, cols=cols, sep=sep, merge=merge, group=group)\n",
    "        rows = get_rows(df=df, codes=allcodes, cols=cols, sep=sep, _fix=False)\n",
    "        sub = df[rows]\n",
    "\n",
    "    df_persons = sub.groupby(pid)[cols].apply(lambda s: pd.unique(s.values.ravel()).tolist()).astype(str)\n",
    "\n",
    "    # alternative approach, also good, and avoids creaintg personal dataframe\n",
    "    # but ... regeis is fast since it stopw when it finds one true code!\n",
    "    #    c=df.icdbi.str.split(', ', expand=True).to_sparse()\n",
    "    #    c.isin(['S720', 'I10']).any(axis=1).any(level=0)\n",
    "\n",
    "    persondf = pd.DataFrame(index=df[pid].unique().tolist())\n",
    "    for name, codes in codes.items():\n",
    "        codes_regex = '|'.join(codes)\n",
    "        persondf[name] = df_persons.str.contains(codes_regex, na=False)\n",
    "\n",
    "    return persondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _format_codes(codes, merge=True):\n",
    "    \"\"\"\n",
    "    Makes sure that the codes has the desired format: a dict with strings as\n",
    "    keys (name) and a list of codes as values)\n",
    "\n",
    "    Background: For several functions the user is allower to use strings\n",
    "    when there is only one element in the list, and a list when there is\n",
    "    no code replacement or aggregations, or a dict. To avoid (even more) mess\n",
    "    the input is standardised as soon as possible in a function.\n",
    "\n",
    "    Examples:\n",
    "            codes = '4AB02'\n",
    "            codes='4AB*'\n",
    "            codes = ['4AB02', '4AB04', '4AC*']\n",
    "            codes = ['4AB02', '4AB04']\n",
    "            codes = {'tumor' : 'a4*', 'diabetes': ['d3*', 'd5-d9']}\n",
    "            codes = 'S72*'\n",
    "            codes = ['K50*', 'K51*']\n",
    "\n",
    "            _format_codes(codes, merge=False)\n",
    "\n",
    "    TODO: test for correctness of input, not just reformat (is the key a str?)\n",
    "    \"\"\"\n",
    "    codes = _listify(codes)\n",
    "\n",
    "    # treeatment of pure lists depends on whether special classes should be treated as one merged group or separate codes\n",
    "    # exmple xounting of Z51* could mean count the total number of codes with Z51 OR a shorthand for saying \"count all codes starting with Z51 separately\n",
    "    # The option \"merged, enables the user to switch between these two interpretations\n",
    "\n",
    "    if isinstance(codes, list):\n",
    "        if merge:\n",
    "            codes = {'_'.join(codes): codes}\n",
    "        else:\n",
    "            codes = {code: [code] for code in codes}\n",
    "\n",
    "    elif isinstance(codes, dict):\n",
    "        new_codes = {}\n",
    "        for name, codelist in codes.items():\n",
    "            if isinstance(codelist, str):\n",
    "                codelist = [codelist]\n",
    "            new_codes[name] = codelist\n",
    "        codes = new_codes\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _expand_regex(expr, full_list):\n",
    "    exprs = _listify(expr)\n",
    "\n",
    "    expanded = []\n",
    "\n",
    "    if isinstance(full_list, pd.Series):\n",
    "        pass\n",
    "    elif isinstance(full_list, list):\n",
    "        unique_series = pd.Series(full_list)\n",
    "    elif isinstance(full_list, set):\n",
    "        unique_series = pd.Series(list(full_list))\n",
    "\n",
    "    for expr in exprs:\n",
    "        match = unique_series.str.contains(expr)\n",
    "        expanded.extend(unique_series[match])\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reverse_dict(dikt):\n",
    "    new_dict = {}\n",
    "    for name, codelist in dikt.items():\n",
    "        codelist = _listify(codelist)\n",
    "        new_dict.update({code: name for code in codelist})\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_with(df,\n",
    "                 codes,\n",
    "                 cols,\n",
    "                 pid='pid',\n",
    "                 sep=None,\n",
    "                 merge=True,\n",
    "                 first_date=None,\n",
    "                 last_date=None,\n",
    "                 group=False,\n",
    "                 _fix=True):\n",
    "    \"\"\"\n",
    "    Determine whether people have received a code\n",
    "\n",
    "    Args:\n",
    "        codes (list or dict): codes to mark for\n",
    "            codes to search for\n",
    "                - if list: each code will represent a column\n",
    "                - if dict: the codes in each item will be aggregated to one indicator\n",
    "            cols (str or list of str): Column(s) with the codes\n",
    "            pid (str): colum with the person identifier\n",
    "            first_date (str): use only codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "            last_date (str): only use codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "\n",
    "    Returns:\n",
    "        Series or Dataframe\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        fracture = persons_with(df=df, codes='S72*', cols='icdmain')\n",
    "        fracture = persons_with(df=df, codes={'frac':'S72*'}, cols='icdmain')\n",
    "\n",
    "    Todo:\n",
    "        - function may check if pid_index is unique, in which it does not have to aggregate\n",
    "        - this may apply in general? functions that work on event data may then also work on person level data\n",
    "        - allow user to input person level dataframe source?\n",
    "    \"\"\"\n",
    "    sub = df\n",
    "\n",
    "    if _fix:\n",
    "        df, cols = _to_df(df=df, cols=cols)\n",
    "        codes, cols, allcodes, sep = _fix_args(df=df, codes=codes, cols=cols, sep=sep, merge=merge, group=group)\n",
    "        rows = get_rows(df=df, codes=allcodes, cols=cols, sep=sep, _fix=False)\n",
    "        sub = df[rows]\n",
    "\n",
    "    df_persons = sub.groupby(pid)[cols].apply(lambda s: pd.unique(s.values.ravel()).tolist()).astype(str)\n",
    "\n",
    "    # alternative approach, also good, and avoids creaintg personal dataframe\n",
    "    # but ... regeis is fast since it stopw when it finds one true code!\n",
    "    #    c=df.icdbi.str.split(', ', expand=True).to_sparse()\n",
    "    #    c.isin(['S720', 'I10']).any(axis=1).any(level=0)\n",
    "\n",
    "    persondf = pd.DataFrame(index=df[pid].unique().tolist())\n",
    "    for name, codes in codes.items():\n",
    "        codes_regex = '|'.join(codes)\n",
    "        persondf[name] = df_persons.str.contains(codes_regex, na=False)\n",
    "\n",
    "    return persondf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get inpatient data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the functions and to calculate the Charslon index we need some data. Here we will use data on hospital visits from Medicare: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read synthetic medicare sample data on inpatient hospital stays\n",
    "path = 'https://www.cms.gov/Research-Statistics-Data-and-Systems/Downloadable-Public-Use-Files/SynPUFs/Downloads/'\n",
    "inpatient_file = 'DE1_0_2008_to_2010_Inpatient_Claims_Sample_1.zip'\n",
    "\n",
    "inpatient = pd.read_csv(path+inpatient_file)\n",
    "\n",
    "inpatient.columns = inpatient.columns.str.lower()\n",
    "# easier to use a column called 'pid' than 'desynpuf_id'\n",
    "inpatient['pid']=inpatient['desynpuf_id']\n",
    "\n",
    "#set index to the personal id, but also keep id as a column\n",
    "inpatient = inpatient.set_index('pid', drop=False)\n",
    "inpatient.index.name='pid_index'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look\n",
    "inpatient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of columns with information about diagnostic codes\n",
    "icd_cols = list(inpatient.columns[inpatient.columns.str.startswith('icd9_dgns_cd')])\n",
    "icd_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list of all unique ICD9 codes that exist, a all_codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codes to calculate CCI using ICD-9 (CM, US, Enhanced)\n",
    "# Source: http://mchp-appserv.cpe.umanitoba.ca/concept/Charlson%20Comorbidities%20-%20Coding%20Algorithms%20for%20ICD-9-CM%20and%20ICD-10.pdf\n",
    "\n",
    "infarction = '''\n",
    "      410* \n",
    "      412*\n",
    "      '''\n",
    "\n",
    "heart_failure = '''\n",
    "        390.91 \n",
    "        402.21 402.11 402.91 \n",
    "        404.01 404.03 404.11 404.13 404.91 404.93 \n",
    "        425.4-425.9 \n",
    "        428*\n",
    "        '''\n",
    "\n",
    "peripheral_vascular = '''\n",
    "        093.0\n",
    "        437.3\n",
    "        440*\n",
    "        441*\n",
    "        443.1-443.9\n",
    "        447.1\n",
    "        557.1 557.9\n",
    "        V43.4\n",
    "        '''\n",
    "\n",
    "cerebrovascular = '''\n",
    "        362.34\n",
    "        430*-438*\n",
    "        '''\n",
    "dementia = '''\n",
    "        290*\n",
    "        294.1\n",
    "        331.2\n",
    "        '''\n",
    "\n",
    "pulmonary ='''\n",
    "      416.8 416.9\n",
    "      490*-505* \n",
    "      506.4\n",
    "      508.1 508.8\n",
    "      '''\n",
    "rheumatic = '''\n",
    "      446.5\n",
    "      710.0-710.4\n",
    "      714.0-714.2 714.8\n",
    "      725*\n",
    "      '''\n",
    "\n",
    "peptic_ulcer = '531*-534*'\n",
    "\n",
    "liver_mild ='''\n",
    "      070.22\n",
    "      070.23\n",
    "      070.32\n",
    "      070.33\n",
    "      070.44\n",
    "      070.54\n",
    "      070.6\n",
    "      070.9\n",
    "      570.*\n",
    "      571.*\n",
    "      573.3 573.4 573.8 573.9\n",
    "      V42.7\n",
    "      '''\n",
    "# Interesting, diabetes seems to be 5 digits long in the data, but not the specified codes\n",
    "diabetes_without_complication = '250.0*-250.3* 250.8* 250.9*'\n",
    "\n",
    "diabetes_with_complication = '250.4*-250.7*'\n",
    "\n",
    "plegia = '''\n",
    "    334.1\n",
    "    342.*\n",
    "    343.*\n",
    "    344.0-344.6\n",
    "    344.9\n",
    "    '''\n",
    "\n",
    "renal = '''\n",
    "    403.01 403.11,403.91 \n",
    "    404.02 404.03 404.12 404.13 404.92 404.93\n",
    "    582.*  \n",
    "    583.0-583.7\n",
    "    585*\n",
    "    586*\n",
    "    588.0\n",
    "    V42.0\n",
    "    V45.1\n",
    "    V56*\n",
    "    '''\n",
    "\n",
    "malignancy = '''\n",
    "    140*-172*\n",
    "    174.0-195.8\n",
    "    200*-208*\n",
    "    238.6\n",
    "    '''\n",
    "\n",
    "liver_not_mild = '''\n",
    "    456.0-456.2\n",
    "    572.2-572.8\n",
    "    '''\n",
    "\n",
    "tumor = '196*-199*'\n",
    "\n",
    "hiv = '042*-044*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all the strings that describe the codes for the comorbitities in a single datastructure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd9 = unique(df=inpatient, cols = icd_cols, all_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary with names of cormobitities and the associated medical codes\n",
    "\n",
    "code_string = { 'infarction' : infarction, \n",
    "               'heart_failure' : heart_failure, \n",
    "               'peripheral_vascular' : peripheral_vascular, \n",
    "               'cerebrovascular' : cerebrovascular, \n",
    "               'dementia' : dementia, \n",
    "               'pulmonary' : pulmonary, \n",
    "               'rheumatic' : rheumatic, \n",
    "               'peptic_ulcer' : peptic_ulcer, \n",
    "               'liver_mild' : liver_mild, \n",
    "               'diabetes_without_complication' : diabetes_without_complication, \n",
    "               'diabetes_with_complication' : diabetes_with_complication, \n",
    "               'plegia' : plegia, \n",
    "               'renal' : renal, \n",
    "               'malignancy' : malignancy, \n",
    "               'liver_not_mild' : liver_not_mild, \n",
    "               'tumor' : tumor, \n",
    "               'hiv' : hiv}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having created a all_codes, we can use the functions we have created to expand the description for all the different comorbidities to include all the specific codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {disease : expand_code(codes.split(), \n",
    "                               all_codes=icd9,\n",
    "                               drop_dot=True,\n",
    "                               drop_leading_zero=True) \n",
    "        for disease, codes in code_string.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check if it really expanded the codes, for instance by examining the codes for mild liver disease:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes['liver_mild']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do the calculations, we need the weights associated with each comorbidity. These weights are related to the predictive power of the comorbididy for the probability of dying in a given time period. There are a few different standards, but with relatively minor varitions. Here we use the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charlson_points = { 'infarction': 1, \n",
    "                   'heart_failure': 1, \n",
    "                   'peripheral_vascular': 1, \n",
    "                   'cerebrovascular': 1, \n",
    "                   'dementia': 1, \n",
    "                   'pulmonary': 1, \n",
    "                   'rheumatic': 1, \n",
    "                   'peptic_ulcer': 1, \n",
    "                   'liver_mild': 1, \n",
    "                   'diabetes_without_complication': 1, \n",
    "                   'diabetes_with_complication': 2, \n",
    "                   'plegia': 2, \n",
    "                   'renal': 2, \n",
    "                   'malignancy': 2, \n",
    "                   'liver_not_mild': 3, \n",
    "                   'tumor': 6, \n",
    "                   'hiv': 6}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the function that takes a set of codes and identifies the rows and persons who have the codes (a function we developed in a previous notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.sync import script2notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted old_functions.ipynb.\n",
      "Converted pattern_finder.ipynb.\n",
      "Converted pattern_finder_only.ipynb.\n",
      "Converted utilities.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
