{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing health data\n",
    "## Some examples and notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern_finder.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make data\n",
    "In order to demonstrate the methods and functions, it is useful to have some data. Detailed individual level data on health events are sensitive and difficult to obtain, so we have created a function that generates some fake data that we can play with: *make_data* \n",
    "\n",
    "The function generates a dataframe of a random number of events for *n* individuals. Each individual will be a assigned an id, a birth date and a geographic region. Each individual will also have one or more health events that are associated with a date and one or more medical codes. These codes could describe a diagnosis, a medical procedure, a prescription and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1930-02-27</td>\n",
       "      <td>1935-09-24</td>\n",
       "      <td>north</td>\n",
       "      <td>M23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1929-11-22</td>\n",
       "      <td>1932-07-19</td>\n",
       "      <td>north</td>\n",
       "      <td>J63,B72,M37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1929-11-22</td>\n",
       "      <td>1932-08-22</td>\n",
       "      <td>north</td>\n",
       "      <td>V97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1929-11-22</td>\n",
       "      <td>1933-04-10</td>\n",
       "      <td>north</td>\n",
       "      <td>T83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1929-11-22</td>\n",
       "      <td>1933-10-29</td>\n",
       "      <td>north</td>\n",
       "      <td>F60,I70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-01-13</td>\n",
       "      <td>1992-02-03</td>\n",
       "      <td>west</td>\n",
       "      <td>P10,J6,U10,C30,E59,B71,K1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-01-13</td>\n",
       "      <td>1996-09-22</td>\n",
       "      <td>west</td>\n",
       "      <td>H35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-01-13</td>\n",
       "      <td>1997-03-02</td>\n",
       "      <td>west</td>\n",
       "      <td>E7,P40,F7,G88,V22,N31,O5,Z92,W74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-01-13</td>\n",
       "      <td>1998-01-11</td>\n",
       "      <td>west</td>\n",
       "      <td>Y25,P27,L9,B3,G58,C25,H35,E80,T89,U26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>1963-01-13</td>\n",
       "      <td>2000-10-21</td>\n",
       "      <td>west</td>\n",
       "      <td>I73,R19,Z95,L33,A22,M92,I67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5404 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pid  gender birth_date       date region  \\\n",
       "1     1  female 1930-02-27 1935-09-24  north   \n",
       "2     2    male 1929-11-22 1932-07-19  north   \n",
       "2     2    male 1929-11-22 1932-08-22  north   \n",
       "2     2    male 1929-11-22 1933-04-10  north   \n",
       "2     2    male 1929-11-22 1933-10-29  north   \n",
       "..  ...     ...        ...        ...    ...   \n",
       "99   99  female 1963-01-13 1992-02-03   west   \n",
       "99   99  female 1963-01-13 1996-09-22   west   \n",
       "99   99  female 1963-01-13 1997-03-02   west   \n",
       "99   99  female 1963-01-13 1998-01-11   west   \n",
       "99   99  female 1963-01-13 2000-10-21   west   \n",
       "\n",
       "                                    codes  \n",
       "1                                     M23  \n",
       "2                             J63,B72,M37  \n",
       "2                                     V97  \n",
       "2                                     T83  \n",
       "2                                 F60,I70  \n",
       "..                                    ...  \n",
       "99              P10,J6,U10,C30,E59,B71,K1  \n",
       "99                                    H35  \n",
       "99       E7,P40,F7,G88,V22,N31,O5,Z92,W74  \n",
       "99  Y25,P27,L9,B3,G58,C25,H35,E80,T89,U26  \n",
       "99            I73,R19,Z95,L33,A22,M92,I67  \n",
       "\n",
       "[5404 rows x 6 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = make_data(n=100)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the codes are merged in one column. If you want the codes to be in separate columns, you can use *expand=True*. You can also use *columns* to specify that you only want some rows, *letters* and 'numbers' to number to limit the number of different letters of numbers to use in the codes. The dataframe is the result of a random draw of patients and events, but if you want to generate the same dataframe each time, you can use seed=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>gender</th>\n",
       "      <th>code_0</th>\n",
       "      <th>code_1</th>\n",
       "      <th>code_2</th>\n",
       "      <th>code_3</th>\n",
       "      <th>code_4</th>\n",
       "      <th>code_5</th>\n",
       "      <th>code_6</th>\n",
       "      <th>code_7</th>\n",
       "      <th>code_8</th>\n",
       "      <th>code_9</th>\n",
       "      <th>code_10</th>\n",
       "      <th>code_11</th>\n",
       "      <th>code_12</th>\n",
       "      <th>code_13</th>\n",
       "      <th>code_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>A4</td>\n",
       "      <td>B1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>C1</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "      <td>C2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>D1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>D3</td>\n",
       "      <td>A4</td>\n",
       "      <td>C4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>D1</td>\n",
       "      <td>B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>D3</td>\n",
       "      <td>C4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>A4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>C1</td>\n",
       "      <td>A1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>female</td>\n",
       "      <td>C4</td>\n",
       "      <td>C4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4879 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pid  gender code_0 code_1 code_2 code_3 code_4 code_5 code_6 code_7  \\\n",
       "1     1  female     A4     B1    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1     1  female     C1     C4     D4     C2    NaN    NaN    NaN    NaN   \n",
       "1     1  female     D1    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1     1  female     D3     A4     C4    NaN    NaN    NaN    NaN    NaN   \n",
       "1     1  female     D1     B2    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "..  ...     ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "99   99  female     C1    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "99   99  female     D3     C4    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "99   99  female     A4    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "99   99  female     C1     A1    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "99   99  female     C4     C4    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "   code_8 code_9 code_10 code_11 code_12 code_13 code_14  \n",
       "1     NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "1     NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "..    ...    ...     ...     ...     ...     ...     ...  \n",
       "99    NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "99    NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "99    NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "99    NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "99    NaN    NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[4879 rows x 17 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_data(n=100, expand=True, columns=['pid', 'gender', 'codes'], letters=3, numbers=5, seed=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count_codes\n",
    "A common question when given a dataset of different events, is which medical codes are used most frequently. To asnwer this, you can use the *count_codes* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codes']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'U29'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-dc8caf36c215>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcount_codes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'codes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Google Drive\\python\\pattern_finder\\pattern_finder\\utils.py\u001b[0m in \u001b[0;36mcount_codes\u001b[1;34m(df, codes, cols, sep, normalize, ascending, fix, merge, group, dropna, all_codes, info)\u001b[0m\n\u001b[0;32m    955\u001b[0m                         \u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                         \u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                     for col in cols]\n\u001b[0m\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[0mcount_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\python\\pattern_finder\\pattern_finder\\utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    955\u001b[0m                         \u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m                         \u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m                     for col in cols]\n\u001b[0m\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[0mcount_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5691\u001b[0m             results = [\n\u001b[0;32m   5692\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5693\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5694\u001b[0m             ]\n\u001b[0;32m   5695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   5691\u001b[0m             results = [\n\u001b[0;32m   5692\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5693\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5694\u001b[0m             ]\n\u001b[0;32m   5695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5697\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5698\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5699\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;31m# dispatch on extension dtype if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_array_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_from_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py\u001b[0m in \u001b[0;36m_from_sequence\u001b[1;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_from_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, sparse_index, index, fill_value, kind, dtype, copy)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msparse_index\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m             sparse_values, sparse_index, fill_value = make_sparse(\n\u001b[1;32m--> 361\u001b[1;33m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m             )\n\u001b[0;32m    363\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\sparse\\array.py\u001b[0m in \u001b[0;36mmake_sparse\u001b[1;34m(arr, kind, fill_value, dtype, copy)\u001b[0m\n\u001b[0;32m   1536\u001b[0m     \u001b[0msparsified_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1538\u001b[1;33m         \u001b[0msparsified_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparsified_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1539\u001b[0m     \u001b[1;31m# TODO: copy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msparsified_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'U29'"
     ]
    }
   ],
   "source": [
    "count_codes(df=df, cols='codes', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mark rows that contain certain codes in one or more colums\n",
    "def get_rows(df, codes, cols=None, sep=None, pid='pid', all_codes=None, fix=True, info=None):\n",
    "  \"\"\"\n",
    "  Make a boolean series that is true for all rows that contain the codes\n",
    "\n",
    "  Args\n",
    "    df (dataframe or series): The dataframe with codes\n",
    "    codes (str, list, set, dict): codes to be counted\n",
    "    cols (str or list): list of columns to search in\n",
    "    sep (str): The symbol that seperates the codes if there are multiple codes in a cell\n",
    "    pid (str): The name of the column with the personal identifier\n",
    "\n",
    "  >>>get_rows(df=df, codes='F3', cols='codes', sep=',')\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # check if evaluated previously\n",
    "  info, rows = memory(info=info, func = 'get_rows', expr=codes)\n",
    "  if rows:\n",
    "    return rows\n",
    "\n",
    "  # check if codes and columns need to be expanded (needed if they use notation)\n",
    "  if fix:\n",
    "    # do this when if cols exist, but if it does not ...\n",
    "    cols = expand_columns(cols, all_columns=list(df.columns), info=info)\n",
    "    all_codes = sorted(unique(df=df, cols=cols, sep=sep))\n",
    "    codes = expand_code(codes, all_codes=all_codes)\n",
    "\n",
    "  # codes and cols should be lists\n",
    "  codes = listify(codes)\n",
    "  cols = listify(cols)\n",
    "\n",
    "  # approach depends on whether we have multi-value cells or not\n",
    "  # if sep exist, then have multi-value cells\n",
    "  if sep:\n",
    "    # have multi-valued cells\n",
    "    # note: this assumes the sep is a regex word delimiter\n",
    "    codes = [rf'\\b{code}\\b' for code in codes]\n",
    "    codes_regex = '|'.join(codes)\n",
    "\n",
    "    # starting point: no codes have been found\n",
    "    # needed since otherwise the function might return None if no codes exist\n",
    "    rows = pd.Series(False*len(df),index=df.index)\n",
    "\n",
    "   # loop over all columns and mark when a code exist\n",
    "    for col in cols:\n",
    "      rows=rows | df[col].str.contains(codes_regex, na=False)\n",
    "\n",
    "  # if not multi valued cells\n",
    "  else:\n",
    "    mask = df[cols].isin(codes)\n",
    "    rows = mask.any(axis=1)\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_codes(df, codes, cols=None, sep=None, new_sep=',', na_rep='',\n",
    "                  prefix=None, merge=False, out='bool', fix=True, \n",
    "                  series=True, group=False, all_codes=None, info=None):\n",
    "    \"\"\"\n",
    "    Produce one or more columns with only selected codes\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Dataframe with events\n",
    "\n",
    "        codes (string, list or dict): The codes for the disease\n",
    "\n",
    "        cols (string, list): Name of columns where codes are located\n",
    "\n",
    "        sep (string, default: None): Separator between codes in same cell (if exist)\n",
    "            (If None, the function will infer the separator)\n",
    "\n",
    "        pid (str, default: 'pid'): Name of column with the personal identification number\n",
    "\n",
    "        codebook (list): User specified list of all possible or allowed codes\n",
    "\n",
    "        merge (bool): Content of all columns is merged to one series # only if out='text'?\n",
    "\n",
    "        group (bool): Star an other notation remain a single group, not split into individual codes\n",
    "\n",
    "        out (string, ['text', 'category', 'bool' or 'int']): Datatype of output column(s)\n",
    "\n",
    "    Notes:\n",
    "        Can produce a set of dummy columns for codes and code groups.\n",
    "        Can also produce a merged column with only extracted codes.\n",
    "        Accept star notation.\n",
    "        Also accepts both single value columns and columns with compound codes and separators\n",
    "        Repeat events in same rows are only extracted once\n",
    "\n",
    "\n",
    "    Example:\n",
    "    to create three dummy columns, based on codes in icdmain column:\n",
    "\n",
    "    >>> extract_codes(df=df,\n",
    "    >>>          codes={'fracture' : 'S72*', 'cd': 'K50*', 'uc': 'K51*'},\n",
    "    >>>          cols=['icdmain', 'icdbi'],\n",
    "    >>>          merge=False,\n",
    "    >>>          out='text')\n",
    "\n",
    "    extract_codes(df=df, codes={'b':['A1','F3'], 'c':'c*'}, cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes={'b':['A1','F3'], 'c':'C*'}, cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes=['A1','F3', 'C*'], cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes='C*', cols='codes', sep=',', merge = False)\n",
    "\n",
    "    nb: problem with extract rows if dataframe is empty (none of the requested codes)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(df, pd.Series):\n",
    "        df=df.to_frame()\n",
    "        cols=[df.columns]\n",
    "    \n",
    "    if not cols:\n",
    "        cols=[df.columns]\n",
    "        \n",
    "    if fix:\n",
    "        cols=expand_columns(cols, all_columns=list(df.columns))\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep)\n",
    "        \n",
    "        if isinstance(codes, str):\n",
    "            codes=listify(codes)\n",
    "        if (isinstance(codes, list)) and (not merge):\n",
    "            codes = expand_code(codes, all_codes=all_codes, info=info)       \n",
    "            codes = {code:code for code in codes}\n",
    "        if (isinstance(codes, list)) and (merge):\n",
    "            codes = {str(tuple(codes)):codes}\n",
    "            codes = expand_code(codes, all_codes=all_codes, info=info)    \n",
    "        print('after fix', cols, codes)\n",
    "          \n",
    "    subset = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for k, v in codes.items():\n",
    "        if v:\n",
    "          rows = get_rows(df=df, codes=v, cols=cols, sep=sep, all_codes=all_codes, fix=False)\n",
    "        else:\n",
    "          rows=False\n",
    "\n",
    "        if out == 'bool':\n",
    "            subset[k] = rows\n",
    "        elif out == 'int':\n",
    "            subset[k] = rows.astype(int)\n",
    "        elif out == 'category':\n",
    "            subset.loc[rows, k] = k\n",
    "            subset[k] = subset[k].astype('category')\n",
    "        else:\n",
    "            subset[k] = na_rep\n",
    "            subset.loc[rows, k] = k\n",
    "\n",
    "    if (merge) and (out == 'bool'):\n",
    "        subset = subset.astype(int).astype(str)\n",
    "\n",
    "    new_codes = list(subset.columns)\n",
    "\n",
    "    if (merge) and (len(codes) > 1):\n",
    "        headline = ', '.join(new_codes)\n",
    "        merged = subset.iloc[:, 0].str.cat(subset.iloc[:, 1:].values, sep=new_sep,\n",
    "                                           na_rep=na_rep)  # strange .T.values seemed to work previouslyi but it should not have\n",
    "        merged = merged.str.strip(',')\n",
    "        subset = merged\n",
    "        subset.name = headline\n",
    "        if out == 'category':\n",
    "            subset = subset.astype('category')\n",
    "\n",
    "    # return a series if only one code is asked for (and also if merged?)\n",
    "    if series and (len(codes) == 1):\n",
    "        subset = subset.squeeze()\n",
    "\n",
    "    return subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 'C*', 's': ['D2', 'D3']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>b</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4879 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    b  s\n",
       "1   b   \n",
       "1   b   \n",
       "1   b   \n",
       "1   b   \n",
       "1   b  s\n",
       ".. .. ..\n",
       "99  b   \n",
       "99  b   \n",
       "99  b   \n",
       "99  b   \n",
       "99  b   \n",
       "\n",
       "[4879 rows x 2 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_codes(df=df, \n",
    "              codes={'b':'C*', 's':['D2', 'D3']}, \n",
    "              cols='codes', \n",
    "              sep=',',\n",
    "             out='text')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Info():\n",
    "  \"\"\"\n",
    "  A class to store information about the data and results from analysis\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "      self.evaluated = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def memory(info, func, expr):\n",
    "  \"\"\"\n",
    "  checks if the function has been called with the same argument previously and\n",
    "  if so, returns the same results instead of running the function again\n",
    "\n",
    "  args:\n",
    "    -\n",
    "  \"\"\"\n",
    "  rows=None\n",
    "  if info:\n",
    "    if func in info.evaluated:\n",
    "      if expr in info.evaluated[func]:\n",
    "        rows = info.evaluated[func][expr]\n",
    "    else:\n",
    "      info.evaluated[func] = {}\n",
    "  else:\n",
    "    info = Info()\n",
    "    info.evaluated[func] = {}\n",
    "  return info, rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def listify(string_or_list):\n",
    "    \"\"\"\n",
    "    return a list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Args:\n",
    "        string_or_list (str or any):\n",
    "\n",
    "    Returns:\n",
    "        A list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Note:\n",
    "        - allows user to use a string as an argument instead of single lists\n",
    "        - cols='icd10' is allowed instead of cols=['icd10']\n",
    "        - cols='icd10' is transformed to cols=['icd10'] by this function\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(string_or_list, str):\n",
    "        string_or_list = [string_or_list]\n",
    "    return string_or_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dikt):\n",
    "    new_dict = {}\n",
    "    for name, codelist in dikt.items():\n",
    "        codelist = _listify(codelist)\n",
    "        new_dict.update({code: name for code in codelist})\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del dot and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def del_dot(code):\n",
    "  if isinstance(code, str):\n",
    "    return code.replace('.','')\n",
    "  else:\n",
    "    codes = [c.replace('.','') for c in code]\n",
    "  return codes\n",
    "\n",
    "def del_zero(code, left=True, right=False):\n",
    "  if isinstance(codes, str):\n",
    "    codes=[code]\n",
    "  if left:\n",
    "    codes = [c.lstrip('0') for c in code]\n",
    "  if right:\n",
    "    codes = [c.rstrip('0') for c in code]\n",
    "  if isinstance(code, str):\n",
    "    codes=codes[0]\n",
    "  return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# function to expand a string like 'K51.2-K53.8' to a list of codes\n",
    "\n",
    "# Need regex to extract the number component of the input string\n",
    "\n",
    "# The singledispach decorator enables us to have the same name, but use\n",
    "# different functions depending on the datatype of the first argument.\n",
    "#\n",
    "# In our case we want one function to deal with a single string input, and\n",
    "# another to handle a list of strings. It could all be handled in a single\n",
    "# function using nested if, but singledispatch makes it less messy and more fun!\n",
    "\n",
    "\n",
    "# Here is the main function, it is just the name and an error message if the\n",
    "# argument does not fit any of the inputs that wil be allowed\n",
    "\n",
    "@singledispatch\n",
    "def expand_hyphen(expr):\n",
    "  \"\"\"\n",
    "  Expands codes expression(s) that have hyphens to list of all codes\n",
    "\n",
    "  Args:\n",
    "      code (str or list of str): String or list of strings to be expanded\n",
    "\n",
    "  Returns:\n",
    "      List of strings\n",
    "\n",
    "  Examples:\n",
    "      expand_hyphen('C00-C26')\n",
    "      expand_hyphen('b01.1*-b09.9*')\n",
    "      expand_hyphen('n02.2-n02.7')\n",
    "      expand_hyphen('c00*-c260')\n",
    "      expand_hyphen('b01-b09')\n",
    "      expand_hyphen('b001.1*-b009.9*')\n",
    "      expand_hyphen(['b001.1*-b009.9*', 'c11-c15'])\n",
    "  Note:\n",
    "      Unequal number of decimals in start and end code is problematic.\n",
    "      Example: C26.0-C27.11 will not work since the meaning is not obvious:\n",
    "      Is the step size 0.01? In which case C27.1 will not be included, while\n",
    "      C27.10 will be (and traing zeros can be important in codes)\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "# register the function to be used if the input is a string\n",
    "@expand_hyphen.register(str)\n",
    "def _(expr):\n",
    "    # return immediately if nothing to expand\n",
    "    if '-' not in expr:\n",
    "      return [expr]\n",
    "\n",
    "    lower, upper = expr.split('-')\n",
    "\n",
    "    lower=lower.strip()\n",
    "\n",
    "    # identify the numeric component of the code\n",
    "    lower_str = re.search(\"\\d*\\.\\d+|\\d+\", lower).group()\n",
    "    upper_str = re.search(\"\\d*\\.\\d+|\\d+\", upper).group()\n",
    "    # note: what about european decimal notation?\n",
    "    # also note: what if multiple groups K50.1J8.4-etc\n",
    "\n",
    "\n",
    "    lower_num = int(lower_str.replace('.',''))\n",
    "    upper_num = int(upper_str.replace('.','')) +1\n",
    "\n",
    "    if upper_num<lower_num:\n",
    "      raise ValueError('The start code cannot have a higher number than the end code')\n",
    "\n",
    "    # remember length in case of leading zeros\n",
    "    length = len(lower_str)\n",
    "\n",
    "    nums = range(lower_num, upper_num)\n",
    "\n",
    "    # must use integers in a loop, not floats\n",
    "    # which also means that we must multiply and divide to get decimal back\n",
    "    # and take care of leading and trailing zeros that may disappear\n",
    "    if '.' in lower_str:\n",
    "      lower_decimals = len(lower_str.split('.')[1])\n",
    "      upper_decimals = len(upper_str.split('.')[1])\n",
    "      if lower_decimals==upper_decimals:\n",
    "        multiplier = 10**lower_decimals\n",
    "        codes = [lower.replace(lower_str, format(num /multiplier, f'.{lower_decimals}f').zfill(length)) for num in nums]\n",
    "      # special case: allow k1.1-k1.123, but not k.1-k2.123 the last is ambigious: should it list k2.0 only 2.00?\n",
    "      elif (lower_decimals<upper_decimals) & (upper_str.split('.')[0]==lower_str.split('.')[0]):\n",
    "        from_decimal = int(lower_str.split('.')[1])\n",
    "        to_decimal = int(upper_str.split('.')[1]) +1\n",
    "        nums = range(from_decimal, to_decimal)\n",
    "        decimal_str = '.'+lower.split('.')[1]\n",
    "        codes = [lower.replace(decimal_str, '.'+str(num)) for num in nums]\n",
    "      else:\n",
    "        raise ValueError('The start code and the end code do not have the same number of decimals')\n",
    "    else:\n",
    "        codes = [lower.replace(lower_str, str(num).zfill(length)) for num in nums]\n",
    "    return codes\n",
    "\n",
    "\n",
    "# register the function to be used if if the input is a list of strings\n",
    "@expand_hyphen.register(list)\n",
    "def _(expr):\n",
    "  extended = []\n",
    "  for word in expr:\n",
    "    extended.extend(expand_hyphen(word))\n",
    "  return extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# A function to expand a string with star notation (K50*)\n",
    "# to list of all codes starting with K50\n",
    "\n",
    "@singledispatch\n",
    "def expand_star(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with star notation to a list of all values with the specified pattern\n",
    "\n",
    "  Args:\n",
    "    expr (str or list): Expression (or list of expressions) to be expanded\n",
    "    all_codes (list) : A list of all codes\n",
    "\n",
    "  Examples:\n",
    "    expand_star('K50*', all_codes=icd9)\n",
    "    expand_star('K*5', all_codes=icd9)\n",
    "    expand_star('*5', all_codes=icd9)\n",
    "\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_star.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  # return immediately if there is nothing to expand\n",
    "  if '*' not in code:\n",
    "    return [code]\n",
    "\n",
    "  start_str, end_str = code.split('*')\n",
    "\n",
    "  if start_str and end_str:\n",
    "    codes = {code for code in all_codes if (code.startswith(start_str) & code.endswith(end_str))}\n",
    "\n",
    "  if start_str:\n",
    "    codes = {code for code in all_codes if code.startswith(start_str)}\n",
    "\n",
    "  if end_str:\n",
    "    codes = {code for code in all_codes if code.endswith(end_str)}\n",
    "\n",
    "  return sorted(list(codes))\n",
    "\n",
    "@expand_star.register(list)\n",
    "def _(code, all_codes=None):\n",
    "\n",
    "  expanded=[]\n",
    "  for star_code in code:\n",
    "    new_codes = expand_star(star_code, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# function to get all codes in a list between the specified start and end code\n",
    "# Example: Get all codes between K40:L52\n",
    "\n",
    "@singledispatch\n",
    "def expand_colon(code, all_codes=None):\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_colon.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with colon notation to a list of complete code names\n",
    "  code (str or list): Expression (or list of expressions) to be expanded\n",
    "  all_codes (list or array) : The list to slice from\n",
    "\n",
    "  Examples\n",
    "    K50:K52\n",
    "    K50.5:K52.19\n",
    "    A3.0:A9.3\n",
    "\n",
    "  Note: This is different from hyphen and star notation because it can handle\n",
    "  different code lengths and different number of decimals\n",
    "\n",
    "  \"\"\"\n",
    "  if ':' not in code:\n",
    "    return [code]\n",
    "\n",
    "  startstr, endstr = code.split(':')\n",
    "\n",
    "  # remove spaces\n",
    "  startstr = startstr.strip()\n",
    "  endstr =endstr.strip()\n",
    "\n",
    "  # find start and end position\n",
    "  startpos = all_codes.index(startstr)\n",
    "  endpos = all_codes.index(endstr) + 1\n",
    "\n",
    "  # slice list\n",
    "  expanded = all_codes[startpos:endpos+1]\n",
    "\n",
    "  return expanded\n",
    "\n",
    "\n",
    "@expand_colon.register(list)\n",
    "def _(code, all_codes=None, regex=False):\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_colon(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Return all elements in a list that fits a regex pattern\n",
    "\n",
    "@singledispatch\n",
    "def expand_regex(code, all_codes):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_regex.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  code_regex = re.compile(code)\n",
    "  expanded = {code for code in all_codes if code_regex.match(code)}\n",
    "  # uniqify\n",
    "  expanded = list(set(expanded))\n",
    "  return expanded\n",
    "\n",
    "@expand_regex.register(list)\n",
    "def _(code, all_codes):\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_regex(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = sorted(list(set(expanded)))\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@singledispatch\n",
    "def expand_code(code, all_codes=None,\n",
    "                hyphen=True, star=True, colon=True, regex=False,\n",
    "                drop_dot=False, drop_leading_zero=False,\n",
    "                sort_unique=True, info=None):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_code.register(str)\n",
    "def _(code, all_codes=None,\n",
    "      hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "  #validating input\n",
    "  if (not regex) and (':' in code) and (('-' in code) or ('*' in code)):\n",
    "    raise ValueError('Notation using colon must start from and end in specific codes, not codes using star or hyphen')\n",
    "\n",
    "  if regex:\n",
    "    codes = expand_regex(code, all_codes=all_codes)\n",
    "    return codes\n",
    "\n",
    "  if drop_dot:\n",
    "    code = del_dot(code)\n",
    "\n",
    "  codes=[code]\n",
    "\n",
    "  if hyphen:\n",
    "    codes=expand_hyphen(code)\n",
    "  if star:\n",
    "    codes=expand_star(codes, all_codes=all_codes)\n",
    "  if colon:\n",
    "    codes=expand_colon(codes, all_codes=all_codes)\n",
    "\n",
    "  if sort_unique:\n",
    "    codes = sorted(list(set(codes)))\n",
    "\n",
    "  return codes\n",
    "\n",
    "@expand_code.register(list)\n",
    "def _(code, all_codes=None, hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_code(cod, all_codes=all_codes, hyphen=hyphen, star=star, colon=colon, regex=regex, drop_dot=drop_dot, drop_leading_zero=drop_leading_zero)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)\n",
    "\n",
    "# a dict of names and codes (in a string or a list)\n",
    "@expand_code.register(dict)\n",
    "def _(code, all_codes=None, hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "\n",
    "  expanded={}\n",
    "\n",
    "  for name, cod in code.items():\n",
    "    if isinstance(cod,str):\n",
    "        cod = [cod]\n",
    "    expanded_codes=[]\n",
    "    for co in cod:\n",
    "        new_codes = expand_code(co, all_codes=all_codes, hyphen=hyphen, star=star, colon=colon, regex=regex, drop_dot=drop_dot, drop_leading_zero=drop_leading_zero)\n",
    "        expanded_codes.extend(new_codes)\n",
    "    expanded[name] = list(set(expanded_codes))\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes={'F3':'F3'}\n",
    "all_codes=['G3', 'F3']\n",
    "expand_code(codes, all_codes=all_codes)\n",
    "cod=[]\n",
    "cod.extend('H3')\n",
    "cod\n",
    "expand_code('F3', all_codes=all_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@singledispatch\n",
    "def expand_columns(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    \"\"\"\n",
    "    Expand columns with special notation to their full column names\n",
    "\n",
    "    \"\"\"\n",
    "    raise ValueError('Must be str or list of str')\n",
    "\n",
    "@expand_columns.register(str)\n",
    "def _(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    notations = '* - :'.split()\n",
    "    # return immediately if not needed\n",
    "    if not any(symbol in expr for symbol in notations):\n",
    "      return [expr]\n",
    "\n",
    "    # get a list of columns of it is only implicity defined by the df\n",
    "    # warning: may depreciate this, require explicit all_columns\n",
    "    if df & (not all_columns):\n",
    "      all_columns=list(df.columns)\n",
    "\n",
    "    if regex:\n",
    "      cols = [col for col in all_columns if re.match(regex, expr)]\n",
    "    else:\n",
    "      if hyphen:\n",
    "        cols = expand_hyphen(expr)\n",
    "      if star:\n",
    "        cols = expand_star(expr, all_codes=all_columns)\n",
    "      if colon:\n",
    "        cols = expand_colon(expr, all_codes=all_columns)\n",
    "\n",
    "    return cols\n",
    "\n",
    "@expand_columns.register(list)\n",
    "def _(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    all_columns=[]\n",
    "    for col in expr:\n",
    "        new_columns = expand_columns(col, all_columns=all_columns, df=df, star=star,\n",
    "                       hyphen=hyphen, colon=colon, regex=regex, info=info)\n",
    "        all_columns.extend(new_columns)\n",
    "    return all_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_codes(codes, merge=True):\n",
    "    \"\"\"\n",
    "    Makes sure that the codes has the desired format: a dict with strings as\n",
    "    keys (name) and a list of codes as values)\n",
    "\n",
    "    Background: For several functions the user is allower to use strings\n",
    "    when there is only one element in the list, and a list when there is\n",
    "    no code replacement or aggregations, or a dict. To avoid (even more) mess\n",
    "    the input is standardised as soon as possible in a function.\n",
    "\n",
    "    Examples:\n",
    "            codes = '4AB02'\n",
    "            codes='4AB*'\n",
    "            codes = ['4AB02', '4AB04', '4AC*']\n",
    "            codes = ['4AB02', '4AB04']\n",
    "            codes = {'tumor' : 'a4*', 'diabetes': ['d3*', 'd5-d9']}\n",
    "            codes = 'S72*'\n",
    "            codes = ['K50*', 'K51*']\n",
    "\n",
    "            _format_codes(codes, merge=False)\n",
    "\n",
    "    TODO: test for correctness of input, not just reformat (is the key a str?)\n",
    "    \"\"\"\n",
    "    codes = _listify(codes)\n",
    "\n",
    "    # treeatment of pure lists depends on whether special classes should be treated as one merged group or separate codes\n",
    "    # exmple xounting of Z51* could mean count the total number of codes with Z51 OR a shorthand for saying \"count all codes starting with Z51 separately\n",
    "    # The option \"merged, enables the user to switch between these two interpretations\n",
    "\n",
    "    if isinstance(codes, list):\n",
    "        if merge:\n",
    "            codes = {'_'.join(codes): codes}\n",
    "        else:\n",
    "            codes = {code: [code] for code in codes}\n",
    "\n",
    "    elif isinstance(codes, dict):\n",
    "        new_codes = {}\n",
    "        for name, codelist in codes.items():\n",
    "            if isinstance(codelist, str):\n",
    "                codelist = [codelist]\n",
    "            new_codes[name] = codelist\n",
    "        codes = new_codes\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _expand_regex(expr, full_list):\n",
    "    exprs = _listify(expr)\n",
    "\n",
    "    expanded = []\n",
    "\n",
    "    if isinstance(full_list, pd.Series):\n",
    "        pass\n",
    "    elif isinstance(full_list, list):\n",
    "        unique_series = pd.Series(full_list)\n",
    "    elif isinstance(full_list, set):\n",
    "        unique_series = pd.Series(list(full_list))\n",
    "\n",
    "    for expr in exprs:\n",
    "        match = unique_series.str.contains(expr)\n",
    "        expanded.extend(unique_series[match])\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reverse_dict(dikt):\n",
    "    new_dict = {}\n",
    "    for name, codelist in dikt.items():\n",
    "        codelist = _listify(codelist)\n",
    "        new_dict.update({code: name for code in codelist})\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_with(df,\n",
    "                 codes,\n",
    "                 cols,\n",
    "                 pid='pid',\n",
    "                 sep=None,\n",
    "                 merge=True,\n",
    "                 first_date=None,\n",
    "                 last_date=None,\n",
    "                 group=False,\n",
    "                 _fix=True):\n",
    "    \"\"\"\n",
    "    Determine whether people have received a code\n",
    "\n",
    "    Args:\n",
    "        codes (list or dict): codes to mark for\n",
    "            codes to search for\n",
    "                - if list: each code will represent a column\n",
    "                - if dict: the codes in each item will be aggregated to one indicator\n",
    "            cols (str or list of str): Column(s) with the codes\n",
    "            pid (str): colum with the person identifier\n",
    "            first_date (str): use only codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "            last_date (str): only use codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "\n",
    "    Returns:\n",
    "        Series or Dataframe\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        fracture = persons_with(df=df, codes='S72*', cols='icdmain')\n",
    "        fracture = persons_with(df=df, codes={'frac':'S72*'}, cols='icdmain')\n",
    "\n",
    "    Todo:\n",
    "        - function may check if pid_index is unique, in which it does not have to aggregate\n",
    "        - this may apply in general? functions that work on event data may then also work on person level data\n",
    "        - allow user to input person level dataframe source?\n",
    "    \"\"\"\n",
    "    sub = df\n",
    "\n",
    "    if _fix:\n",
    "        df, cols = _to_df(df=df, cols=cols)\n",
    "        codes, cols, allcodes, sep = _fix_args(df=df, codes=codes, cols=cols, sep=sep, merge=merge, group=group)\n",
    "        rows = get_rows(df=df, codes=allcodes, cols=cols, sep=sep, _fix=False)\n",
    "        sub = df[rows]\n",
    "\n",
    "    df_persons = sub.groupby(pid)[cols].apply(lambda s: pd.unique(s.values.ravel()).tolist()).astype(str)\n",
    "\n",
    "    # alternative approach, also good, and avoids creaintg personal dataframe\n",
    "    # but ... regeis is fast since it stopw when it finds one true code!\n",
    "    #    c=df.icdbi.str.split(', ', expand=True).to_sparse()\n",
    "    #    c.isin(['S720', 'I10']).any(axis=1).any(level=0)\n",
    "\n",
    "    persondf = pd.DataFrame(index=df[pid].unique().tolist())\n",
    "    for name, codes in codes.items():\n",
    "        codes_regex = '|'.join(codes)\n",
    "        persondf[name] = df_persons.str.contains(codes_regex, na=False)\n",
    "\n",
    "    return persondf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting an expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_external(expr):\n",
    "  \"\"\"\n",
    "  Replaces variables prefixed with @ in the expression with the\n",
    "  value of the variable from the global namespace\n",
    "\n",
    "  Example:\n",
    "      x=['4AB02', '4AB04', '4AB06']\n",
    "      expr = '@x before 4AB02'\n",
    "      insert_external(expr)\n",
    "  \"\"\"\n",
    "  externals = [word.strip('@') for word in expr.split() if word.startswith('@')]\n",
    "  for external in externals:\n",
    "      tmp = globals()[external]\n",
    "      expr = expr.replace(f'@{external} ', f'{tmp} ')\n",
    "  return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A function to identify all unique values in one or more columns\n",
    "# with one or multiple codes in each cell\n",
    "\n",
    "\n",
    "def unique(df, cols=None, sep=None, all_str=True):\n",
    "  \"\"\"\n",
    "  Lists unique values from one or more columns\n",
    "\n",
    "  sep (str): separator if cells have multiple values\n",
    "  all_str (bool): converts all values to strings\n",
    "\n",
    "  unique(df=df, cols='inpatient', sep=',')\n",
    "  \"\"\"\n",
    "  # if no column(s) are specified, find unique values in whole dataframe\n",
    "  if cols==None:\n",
    "    cols=list(df.columns)\n",
    "  cols = listify(cols)\n",
    "\n",
    "  # multiple values with separator in cells\n",
    "  if sep:\n",
    "    all_unique=set()\n",
    "    for col in cols:\n",
    "      new_unique = set(df[col].str.cat(sep=',').split(','))\n",
    "      all_unique.update(new_unique)\n",
    "  # single valued cells\n",
    "  else:\n",
    "    all_unique = pd.unique(df[cols].values.ravel('K'))\n",
    "\n",
    "  # if need to make sure all elements are strings without surrounding spaces\n",
    "  if all_str:\n",
    "    all_unique=[str(value).strip() for value in all_unique]\n",
    "\n",
    "  return all_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_codes(df, codes=None, cols=None, sep=None, normalize=False,\n",
    "                ascending=False, _fix=True, merge=False, group=False, dropna=True):\n",
    "    \"\"\"\n",
    "    Count frequency of values in multiple columns or columns with seperators\n",
    "\n",
    "    Args:\n",
    "        codes (str, list of str, dict): codes to be counted\n",
    "        cols (str or list of str): columns where codes are\n",
    "        sep (str): separator if multiple codes in cells\n",
    "        merge (bool): If False, each code wil be counted separately\n",
    "            If True (default), each code with special notation will be counted together\n",
    "        strip (bool): strip spacec bore and after code before counting\n",
    "        ignore_case (bool): determine if codes with same characters,\n",
    "            but different cases should be the same\n",
    "        normalize (bool): If True, outputs percentages and not absolute numbers\n",
    "\n",
    "    allows\n",
    "        - star notation in codes and columns\n",
    "        - values in cells with multiple valules can be separated (if sep is defined)\n",
    "        - replacement and aggregation to larger groups (when code is a dict)\n",
    "\n",
    "    example\n",
    "    To count the number of stereoid events (codes starting with H2) and use of\n",
    "    antibiotics (codes starting with xx) in all columns where the column names\n",
    "    starts with \"atc\":\n",
    "\n",
    "    count_codes(df=df,\n",
    "                 codes={'stereoids' : 'H2*', 'antibiotics' : =['AI3*']},\n",
    "                 cols='atc*',\n",
    "                 sep=',')\n",
    "\n",
    "    more examples\n",
    "    -------------\n",
    "\n",
    "    df.count_codes(codes='K51*', cols='icd', sep=',')\n",
    "    count_codes(df, codes='K51*', cols='icdm', sep=',', group=True)\n",
    "    count_codes(df, codes='Z51*', cols=['icd', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes='Z51*', cols=['icdmain', 'icdbi'], sep=',', group=True)\n",
    "    count_codes(df, codes={'radiation': 'Z51*'}, cols=['icd'], sep=',')\n",
    "    count_codes(df, codes={'radiation': 'Z51*'}, cols=['icdmain', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=True)\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=False)\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icd'], sep=',', dropna=False, group=True, merge=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False, merge=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False, merge=True)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=True, group=True, merge=True)\n",
    "    #group fasle, merge true, for list = wrong ...\n",
    "\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=True, group=False, merge=False)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # count all if codes is codes is not specified\n",
    "    # use all columns if col is not specified\n",
    "    sub = df\n",
    "\n",
    "    if _fix:\n",
    "        sub, cols = _to_df(df=sub, cols=cols)\n",
    "        cols = _fix_cols(df=sub, cols=cols)\n",
    "        if not sep:\n",
    "            sep = _sniff_sep(df=sub, cols=cols)\n",
    "\n",
    "        if codes:\n",
    "            codes = _format_codes(codes=codes, merge=merge)\n",
    "            codes = expand_codes(df=sub, codes=codes, cols=cols, sep=sep, merge=merge, group=group)\n",
    "            allcodes = _get_allcodes(codes)\n",
    "            if dropna:\n",
    "                rows = get_rows(df=sub, codes=allcodes, cols=cols, sep=sep, _fix=False)\n",
    "                sub = sub[rows]\n",
    "\n",
    "    if sep:\n",
    "        count_df = [sub[col].str\n",
    "                        .split(sep, expand=True)\n",
    "                        .apply(lambda x: x.str.strip())\n",
    "                        .to_sparse()\n",
    "                        .apply(pd.Series.value_counts)\n",
    "                        .sum(axis=1)\n",
    "                    for col in cols]\n",
    "\n",
    "        count_df = pd.DataFrame(count_df).T\n",
    "        code_count = count_df.sum(axis=1)\n",
    "    else:\n",
    "        code_count = sub[cols].apply(pd.Series.value_counts).sum(axis=1)\n",
    "\n",
    "    if codes:\n",
    "        allcodes = _get_allcodes(codes)\n",
    "        not_included_n = code_count[~code_count.isin(allcodes)].sum()\n",
    "        code_count = code_count[allcodes]\n",
    "        if not dropna:\n",
    "            code_count['na'] = not_included_n\n",
    "\n",
    "    if isinstance(codes, dict):\n",
    "        code_count = code_count.rename(index=_reverse_dict(codes)).sum(level=0)\n",
    "\n",
    "    if normalize:\n",
    "        code_n = code_count.sum()\n",
    "        code_count = code_count / code_n\n",
    "    else:\n",
    "        code_count = code_count.astype(int)\n",
    "\n",
    "    if ascending:\n",
    "        code_count = code_count.sort_values(ascending=True)\n",
    "    else:\n",
    "        code_count = code_count.sort_values(ascending=False)\n",
    "\n",
    "    return code_count\n",
    "\n",
    "\n",
    "# %%\n",
    "def lookup_codes(dikt, codes):\n",
    "    \"\"\"\n",
    "    returns those elements in a dict where key starts with the expressions listed in codes\n",
    "\n",
    "    todo: more complicated star notations: starts with, contains, endswith\n",
    "    lookup(medcodes, 'L04*')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    codes = _listify(codes)\n",
    "    codes = [code.upper().strip('*') for code in codes]\n",
    "    codes = tuple(codes)\n",
    "\n",
    "    selected_codes = {k: v for k, v in dikt.items() if str(k).upper().startswith(codes)}\n",
    "    return selected_codes\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_codes(dikt, text):\n",
    "    \"\"\"\n",
    "    returns those elements in a dict where value contains the expressions listed in codes\n",
    "\n",
    "    todo: more complicated star notations: starts with, contains, endswith\n",
    "    alterative name: find_codes? get_codes?\n",
    "\n",
    "    example\n",
    "    get all codes that have \"steroid\" in the explanatory text\n",
    "\n",
    "        get_codes(medcodes, 'steroid*')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text = _listify(text)\n",
    "    text = [txt.upper().strip('*') for txt in text]\n",
    "    # codes = \" \".join(codes)\n",
    "\n",
    "    selected_codes = {k: v for k, v in dikt.items() if any(txt in str(v).upper() for txt in text)}\n",
    "\n",
    "    return selected_codes\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
