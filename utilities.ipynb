{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import singledispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_codes(n=100, letters=26, numbers=100, seed=False):\n",
    "  \"\"\"\n",
    "  Generate a dataframe with a column of random codes\n",
    "\n",
    "  Args:\n",
    "    letters (int): The number of different letters to use\n",
    "    numbers (int): The number of different numbers to use\n",
    "\n",
    "  Returns\n",
    "    A dataframe with a column with one or more codes in the rows\n",
    "\n",
    "  \"\"\"\n",
    "  # each code is assumed to consist of a letter and a number\n",
    "  alphabet = list('abcdefghigjklmnopqrstuvwxyz')\n",
    "  letters=alphabet[:letters+1]\n",
    "\n",
    "  # make random numbers same if seed is specified\n",
    "  if seed:\n",
    "    np.random.seed(0)\n",
    "\n",
    "  # determine the number of codes to be drawn for each event\n",
    "  n_codes=np.random.negative_binomial(1, p=0.3, size=n)\n",
    "  # avoid zero (all events have to have at least one code)\n",
    "  n_codes=n_codes+1\n",
    "\n",
    "  # for each event, randomly generate a the number of codes specified by n_codes\n",
    "  codes=[]\n",
    "  for i in n_codes:\n",
    "      diag = [np.random.choice(letters).upper()+\n",
    "              str(int(np.random.uniform(low=1, high=numbers)))\n",
    "              for num in range(i)]\n",
    "\n",
    "      code_string=','.join(diag)\n",
    "      codes.append(code_string)\n",
    "\n",
    "  # create a dataframe based on the list\n",
    "  df=pd.DataFrame(codes)\n",
    "  df.columns=['code']\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_data(n=100, letters=26, numbers=100, seed=False, expand=False, \n",
    "              columns=['pid', 'gender', 'birth_date', 'date', 'region', 'codes']):\n",
    "  \"\"\"\n",
    "  Generate a dataframe with a column of random codes\n",
    "\n",
    "  Args:\n",
    "    letters (int): The number of different letters to use\n",
    "    numbers (int): The number of different numbers to use\n",
    "\n",
    "  Returns\n",
    "    A dataframe with a column with one or more codes in the rows\n",
    "  \n",
    "  Examples\n",
    "    >>>df = make_data(n=100, letters=5, numbers=5, seed=True)\n",
    "  \"\"\"\n",
    "  \n",
    "  if seed:\n",
    "    np.random.seed(seed=seed)\n",
    "  pid = range(n)\n",
    "  df_person=pd.DataFrame(index = pid)\n",
    "\n",
    "  #female = np.random.binomial(1, 0.5, size =n)\n",
    "  gender = np.random.choice(['male', 'female'], size=n)\n",
    "  region = np.random.choice(['north', 'south', 'east', 'west'], size=n)\n",
    "  birth_year = np.random.randint(1920, 2019, size=n)\n",
    "  birth_month = np.random.randint(1,12, size=n)\n",
    "  birth_day = np.random.randint(1,28, size=n) # ok, I know!\n",
    "  events_per_year = np.random.poisson(1, size=n)\n",
    "  years = 2020 - birth_year\n",
    "  events = years * events_per_year\n",
    "  events = np.where(events==0,1,events)\n",
    "  events = events.astype(int)\n",
    "  all_codes=[]\n",
    "  codes = [all_codes.extend(make_codes(n=n, letters=letters,\n",
    "                                       numbers=numbers,\n",
    "                                       seed=seed)['code'].tolist())\n",
    "          for n in events]\n",
    "\n",
    "  days_alive = (2020 - birth_year) *365\n",
    "\n",
    "  days_and_events = zip(days_alive.tolist(), events.tolist())\n",
    "  all_days=[]\n",
    "  days_after_birth = [all_days.extend(np.random.randint(0, max_day, size=n)) for max_day, n in days_and_events]\n",
    "  pid_and_events = zip(list(pid), events.tolist())\n",
    "  all_pids=[]\n",
    "  pids = [all_pids.extend([p+1]*e) for p, e in pid_and_events]\n",
    "\n",
    "  df_events = pd.DataFrame(index=all_pids)\n",
    "  df_events['codes'] = all_codes\n",
    "  df_events['days_after'] = all_days\n",
    "\n",
    "  #df_person['female'] = female\n",
    "  df_person['gender'] = gender\n",
    "\n",
    "  df_person['region'] = region\n",
    "  df_person['year'] = birth_year\n",
    "  df_person['month'] = birth_month\n",
    "  df_person['day'] = birth_day\n",
    "  df = df_events.merge(df_person, left_index=True, right_index=True)\n",
    "  df['birth_date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "  df['date'] = df['birth_date'] + pd.to_timedelta(df.days_after, unit='d')\n",
    "  del df['month']\n",
    "  del df['day']\n",
    "  del df['days_after']\n",
    "  df['pid'] = df.index\n",
    "  df.index_name = 'pid_index'\n",
    "  df=df.sort_values(['pid', 'date'])\n",
    "  df=df[columns]\n",
    "  \n",
    "  if expand:\n",
    "    splitted = df.codes.str.split(',', expand=True).add_prefix('code_').fillna(np.nan)\n",
    "    df = pd.concat([df,splitted], axis=1)\n",
    "    del df['codes']\n",
    "  # include deaths too?\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# mark rows that contain certain codes in one or more colums\n",
    "def get_rows(df, codes, cols=None, sep=None, pid='pid', all_codes=None, fix=True, info=None):\n",
    "  \"\"\"\n",
    "  Make a boolean series that is true for all rows that contain the codes\n",
    "\n",
    "  Args\n",
    "    df (dataframe or series): The dataframe with codes\n",
    "    codes (str, list, set, dict): codes to be counted\n",
    "    cols (str or list): list of columns to search in\n",
    "    sep (str): The symbol that seperates the codes if there are multiple codes in a cell\n",
    "    pid (str): The name of the column with the personal identifier\n",
    "\n",
    "  >>>get_rows(df=df, codes='F3', cols='codes', sep=',')\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  # check if evaluated previously\n",
    "  info, rows = memory(info=info, func = 'get_rows', expr=codes)\n",
    "  if rows:\n",
    "    return rows\n",
    "\n",
    "  # check if codes and columns need to be expanded (needed if they use notation)\n",
    "  if fix:\n",
    "    # do this when if cols exist, but if it does not ...\n",
    "    cols = expand_columns(cols, all_columns=list(df.columns), info=info)\n",
    "    all_codes = sorted(unique(df=df, cols=cols, sep=sep))\n",
    "    codes = expand_code(codes, all_codes=all_codes)\n",
    "\n",
    "  # codes and cols should be lists\n",
    "  codes = listify(codes)\n",
    "  cols = listify(cols)\n",
    "\n",
    "  # approach depends on whether we have multi-value cells or not\n",
    "  # if sep exist, then have multi-value cells\n",
    "  if sep:\n",
    "    # have multi-valued cells\n",
    "    # note: this assumes the sep is a regex word delimiter\n",
    "    codes = [rf'\\b{code}\\b' for code in codes]\n",
    "    codes_regex = '|'.join(codes)\n",
    "\n",
    "    # starting point: no codes have been found\n",
    "    # needed since otherwise the function might return None if no codes exist\n",
    "    rows = pd.Series(False*len(df),index=df.index)\n",
    "\n",
    "   # loop over all columns and mark when a code exist\n",
    "    for col in cols:\n",
    "      rows=rows | df[col].str.contains(codes_regex, na=False)\n",
    "\n",
    "  # if not multi valued cells\n",
    "  else:\n",
    "    mask = df[cols].isin(codes)\n",
    "    rows = mask.any(axis=1)\n",
    "  return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_codes(df, codes, cols=None, sep=None, new_sep=',', na_rep='',\n",
    "                  prefix=None, merge=False, out='bool', fix=True, \n",
    "                  series=True, group=False, all_codes=None, info=None):\n",
    "    \"\"\"\n",
    "    Produce one or more columns with only selected codes\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): Dataframe with events\n",
    "\n",
    "        codes (string, list or dict): The codes for the disease\n",
    "\n",
    "        cols (string, list): Name of columns where codes are located\n",
    "\n",
    "        sep (string, default: None): Separator between codes in same cell (if exist)\n",
    "            (If None, the function will infer the separator)\n",
    "\n",
    "        pid (str, default: 'pid'): Name of column with the personal identification number\n",
    "\n",
    "        codebook (list): User specified list of all possible or allowed codes\n",
    "\n",
    "        merge (bool): Content of all columns is merged to one series # only if out='text'?\n",
    "\n",
    "        group (bool): Star an other notation remain a single group, not split into individual codes\n",
    "\n",
    "        out (string, ['text', 'category', 'bool' or 'int']): Datatype of output column(s)\n",
    "\n",
    "    Notes:\n",
    "        Can produce a set of dummy columns for codes and code groups.\n",
    "        Can also produce a merged column with only extracted codes.\n",
    "        Accept star notation.\n",
    "        Also accepts both single value columns and columns with compound codes and separators\n",
    "        Repeat events in same rows are only extracted once\n",
    "\n",
    "\n",
    "    Example:\n",
    "    to create three dummy columns, based on codes in icdmain column:\n",
    "\n",
    "    >>> extract_codes(df=df,\n",
    "    >>>          codes={'fracture' : 'S72*', 'cd': 'K50*', 'uc': 'K51*'},\n",
    "    >>>          cols=['icdmain', 'icdbi'],\n",
    "    >>>          merge=False,\n",
    "    >>>          out='text')\n",
    "\n",
    "    extract_codes(df=df, codes={'b':['A1','F3'], 'c':'c*'}, cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes={'b':['A1','F3'], 'c':'C*'}, cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes=['A1','F3', 'C*'], cols='codes', sep=',', merge = False)\n",
    "    extract_codes(df=df, codes='C*', cols='codes', sep=',', merge = False)\n",
    "\n",
    "    nb: problem with extract rows if dataframe is empty (none of the requested codes)\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(df, pd.Series):\n",
    "        df=df.to_frame()\n",
    "        cols=[df.columns]\n",
    "    \n",
    "    if not cols:\n",
    "        cols=[df.columns]\n",
    "        \n",
    "    if fix:\n",
    "        cols=expand_columns(cols, all_columns=list(df.columns))\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep)\n",
    "        \n",
    "        if isinstance(codes, str):\n",
    "            codes=listify(codes)\n",
    "        if (isinstance(codes, list)) and (not merge):\n",
    "            codes = expand_code(codes, all_codes=all_codes, info=info)       \n",
    "            codes = {code:code for code in codes}\n",
    "        if (isinstance(codes, list)) and (merge):\n",
    "            codes = {str(tuple(codes)):codes}\n",
    "            codes = expand_code(codes, all_codes=all_codes, info=info)    \n",
    "        print('after fix', cols, codes)\n",
    "          \n",
    "    subset = pd.DataFrame(index=df.index)\n",
    "\n",
    "    for k, v in codes.items():\n",
    "        if v:\n",
    "          rows = get_rows(df=df, codes=v, cols=cols, sep=sep, all_codes=all_codes, fix=False)\n",
    "        else:\n",
    "          rows=False\n",
    "\n",
    "        if out == 'bool':\n",
    "            subset[k] = rows\n",
    "        elif out == 'int':\n",
    "            subset[k] = rows.astype(int)\n",
    "        elif out == 'category':\n",
    "            subset.loc[rows, k] = k\n",
    "            subset[k] = subset[k].astype('category')\n",
    "        else:\n",
    "            subset[k] = na_rep\n",
    "            subset.loc[rows, k] = k\n",
    "\n",
    "    if (merge) and (out == 'bool'):\n",
    "        subset = subset.astype(int).astype(str)\n",
    "\n",
    "    new_codes = list(subset.columns)\n",
    "\n",
    "    if (merge) and (len(codes) > 1):\n",
    "        headline = ', '.join(new_codes)\n",
    "        merged = subset.iloc[:, 0].str.cat(subset.iloc[:, 1:].values, sep=new_sep,\n",
    "                                           na_rep=na_rep)  # strange .T.values seemed to work previouslyi but it should not have\n",
    "        merged = merged.str.strip(',')\n",
    "        subset = merged\n",
    "        subset.name = headline\n",
    "        if out == 'category':\n",
    "            subset = subset.astype('category')\n",
    "\n",
    "    # return a series if only one code is asked for (and also if merged?)\n",
    "    if series and (len(codes) == 1):\n",
    "        subset = subset.squeeze()\n",
    "\n",
    "    return subset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Info():\n",
    "  \"\"\"\n",
    "  A class to store information about the data and results from analysis\n",
    "  \"\"\"\n",
    "  def __init__(self):\n",
    "      self.evaluated = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def memory(info, func, expr):\n",
    "  \"\"\"\n",
    "  checks if the function has been called with the same argument previously and\n",
    "  if so, returns the same results instead of running the function again\n",
    "\n",
    "  args:\n",
    "    -\n",
    "  \"\"\"\n",
    "  rows=None\n",
    "  if info:\n",
    "    if func in info.evaluated:\n",
    "      if expr in info.evaluated[func]:\n",
    "        rows = info.evaluated[func][expr]\n",
    "    else:\n",
    "      info.evaluated[func] = {}\n",
    "  else:\n",
    "    info = Info()\n",
    "    info.evaluated[func] = {}\n",
    "  return info, rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def listify(string_or_list):\n",
    "    \"\"\"\n",
    "    return a list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Args:\n",
    "        string_or_list (str or any):\n",
    "\n",
    "    Returns:\n",
    "        A list if the input is a string, if not: returns the input as it was\n",
    "\n",
    "    Note:\n",
    "        - allows user to use a string as an argument instead of single lists\n",
    "        - cols='icd10' is allowed instead of cols=['icd10']\n",
    "        - cols='icd10' is transformed to cols=['icd10'] by this function\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(string_or_list, str):\n",
    "        string_or_list = [string_or_list]\n",
    "    return string_or_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def reverse_dict(dikt):\n",
    "    new_dict = {}\n",
    "    for name, codelist in dikt.items():\n",
    "        codelist = _listify(codelist)\n",
    "        new_dict.update({code: name for code in codelist})\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del dot and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def del_dot(code):\n",
    "  if isinstance(code, str):\n",
    "    return code.replace('.','')\n",
    "  else:\n",
    "    codes = [c.replace('.','') for c in code]\n",
    "  return codes\n",
    "\n",
    "def del_zero(code, left=True, right=False):\n",
    "  if isinstance(codes, str):\n",
    "    codes=[code]\n",
    "  if left:\n",
    "    codes = [c.lstrip('0') for c in code]\n",
    "  if right:\n",
    "    codes = [c.rstrip('0') for c in code]\n",
    "  if isinstance(code, str):\n",
    "    codes=codes[0]\n",
    "  return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand hyphen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# function to expand a string like 'K51.2-K53.8' to a list of codes\n",
    "\n",
    "# Need regex to extract the number component of the input string\n",
    "\n",
    "# The singledispach decorator enables us to have the same name, but use\n",
    "# different functions depending on the datatype of the first argument.\n",
    "#\n",
    "# In our case we want one function to deal with a single string input, and\n",
    "# another to handle a list of strings. It could all be handled in a single\n",
    "# function using nested if, but singledispatch makes it less messy and more fun!\n",
    "\n",
    "\n",
    "# Here is the main function, it is just the name and an error message if the\n",
    "# argument does not fit any of the inputs that wil be allowed\n",
    "\n",
    "@singledispatch\n",
    "def expand_hyphen(expr):\n",
    "  \"\"\"\n",
    "  Expands codes expression(s) that have hyphens to list of all codes\n",
    "\n",
    "  Args:\n",
    "      code (str or list of str): String or list of strings to be expanded\n",
    "\n",
    "  Returns:\n",
    "      List of strings\n",
    "\n",
    "  Examples:\n",
    "      expand_hyphen('C00-C26')\n",
    "      expand_hyphen('b01.1*-b09.9*')\n",
    "      expand_hyphen('n02.2-n02.7')\n",
    "      expand_hyphen('c00*-c260')\n",
    "      expand_hyphen('b01-b09')\n",
    "      expand_hyphen('b001.1*-b009.9*')\n",
    "      expand_hyphen(['b001.1*-b009.9*', 'c11-c15'])\n",
    "  Note:\n",
    "      Unequal number of decimals in start and end code is problematic.\n",
    "      Example: C26.0-C27.11 will not work since the meaning is not obvious:\n",
    "      Is the step size 0.01? In which case C27.1 will not be included, while\n",
    "      C27.10 will be (and traing zeros can be important in codes)\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "# register the function to be used if the input is a string\n",
    "@expand_hyphen.register(str)\n",
    "def _(expr):\n",
    "    # return immediately if nothing to expand\n",
    "    if '-' not in expr:\n",
    "      return [expr]\n",
    "\n",
    "    lower, upper = expr.split('-')\n",
    "\n",
    "    lower=lower.strip()\n",
    "\n",
    "    # identify the numeric component of the code\n",
    "    lower_str = re.search(\"\\d*\\.\\d+|\\d+\", lower).group()\n",
    "    upper_str = re.search(\"\\d*\\.\\d+|\\d+\", upper).group()\n",
    "    # note: what about european decimal notation?\n",
    "    # also note: what if multiple groups K50.1J8.4-etc\n",
    "\n",
    "\n",
    "    lower_num = int(lower_str.replace('.',''))\n",
    "    upper_num = int(upper_str.replace('.','')) +1\n",
    "\n",
    "    if upper_num<lower_num:\n",
    "      raise ValueError('The start code cannot have a higher number than the end code')\n",
    "\n",
    "    # remember length in case of leading zeros\n",
    "    length = len(lower_str)\n",
    "\n",
    "    nums = range(lower_num, upper_num)\n",
    "\n",
    "    # must use integers in a loop, not floats\n",
    "    # which also means that we must multiply and divide to get decimal back\n",
    "    # and take care of leading and trailing zeros that may disappear\n",
    "    if '.' in lower_str:\n",
    "      lower_decimals = len(lower_str.split('.')[1])\n",
    "      upper_decimals = len(upper_str.split('.')[1])\n",
    "      if lower_decimals==upper_decimals:\n",
    "        multiplier = 10**lower_decimals\n",
    "        codes = [lower.replace(lower_str, format(num /multiplier, f'.{lower_decimals}f').zfill(length)) for num in nums]\n",
    "      # special case: allow k1.1-k1.123, but not k.1-k2.123 the last is ambigious: should it list k2.0 only 2.00?\n",
    "      elif (lower_decimals<upper_decimals) & (upper_str.split('.')[0]==lower_str.split('.')[0]):\n",
    "        from_decimal = int(lower_str.split('.')[1])\n",
    "        to_decimal = int(upper_str.split('.')[1]) +1\n",
    "        nums = range(from_decimal, to_decimal)\n",
    "        decimal_str = '.'+lower.split('.')[1]\n",
    "        codes = [lower.replace(decimal_str, '.'+str(num)) for num in nums]\n",
    "      else:\n",
    "        raise ValueError('The start code and the end code do not have the same number of decimals')\n",
    "    else:\n",
    "        codes = [lower.replace(lower_str, str(num).zfill(length)) for num in nums]\n",
    "    return codes\n",
    "\n",
    "\n",
    "# register the function to be used if if the input is a list of strings\n",
    "@expand_hyphen.register(list)\n",
    "def _(expr):\n",
    "  extended = []\n",
    "  for word in expr:\n",
    "    extended.extend(expand_hyphen(word))\n",
    "  return extended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# A function to expand a string with star notation (K50*)\n",
    "# to list of all codes starting with K50\n",
    "\n",
    "@singledispatch\n",
    "def expand_star(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with star notation to a list of all values with the specified pattern\n",
    "\n",
    "  Args:\n",
    "    expr (str or list): Expression (or list of expressions) to be expanded\n",
    "    all_codes (list) : A list of all codes\n",
    "\n",
    "  Examples:\n",
    "    expand_star('K50*', all_codes=icd9)\n",
    "    expand_star('K*5', all_codes=icd9)\n",
    "    expand_star('*5', all_codes=icd9)\n",
    "\n",
    "  \"\"\"\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_star.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  # return immediately if there is nothing to expand\n",
    "  if '*' not in code:\n",
    "    return [code]\n",
    "\n",
    "  start_str, end_str = code.split('*')\n",
    "\n",
    "  if start_str and end_str:\n",
    "    codes = {code for code in all_codes if (code.startswith(start_str) & code.endswith(end_str))}\n",
    "\n",
    "  if start_str:\n",
    "    codes = {code for code in all_codes if code.startswith(start_str)}\n",
    "\n",
    "  if end_str:\n",
    "    codes = {code for code in all_codes if code.endswith(end_str)}\n",
    "\n",
    "  return sorted(list(codes))\n",
    "\n",
    "@expand_star.register(list)\n",
    "def _(code, all_codes=None):\n",
    "\n",
    "  expanded=[]\n",
    "  for star_code in code:\n",
    "    new_codes = expand_star(star_code, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand colon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# function to get all codes in a list between the specified start and end code\n",
    "# Example: Get all codes between K40:L52\n",
    "\n",
    "@singledispatch\n",
    "def expand_colon(code, all_codes=None):\n",
    "  raise ValueError('The argument must be a string or a list')\n",
    "\n",
    "@expand_colon.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  \"\"\"\n",
    "  Expand expressions with colon notation to a list of complete code names\n",
    "  code (str or list): Expression (or list of expressions) to be expanded\n",
    "  all_codes (list or array) : The list to slice from\n",
    "\n",
    "  Examples\n",
    "    K50:K52\n",
    "    K50.5:K52.19\n",
    "    A3.0:A9.3\n",
    "\n",
    "  Note: This is different from hyphen and star notation because it can handle\n",
    "  different code lengths and different number of decimals\n",
    "\n",
    "  \"\"\"\n",
    "  if ':' not in code:\n",
    "    return [code]\n",
    "\n",
    "  startstr, endstr = code.split(':')\n",
    "\n",
    "  # remove spaces\n",
    "  startstr = startstr.strip()\n",
    "  endstr =endstr.strip()\n",
    "\n",
    "  # find start and end position\n",
    "  startpos = all_codes.index(startstr)\n",
    "  endpos = all_codes.index(endstr) + 1\n",
    "\n",
    "  # slice list\n",
    "  expanded = all_codes[startpos:endpos+1]\n",
    "\n",
    "  return expanded\n",
    "\n",
    "\n",
    "@expand_colon.register(list)\n",
    "def _(code, all_codes=None, regex=False):\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_colon(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Return all elements in a list that fits a regex pattern\n",
    "\n",
    "@singledispatch\n",
    "def expand_regex(code, all_codes):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_regex.register(str)\n",
    "def _(code, all_codes=None):\n",
    "  code_regex = re.compile(code)\n",
    "  expanded = {code for code in all_codes if code_regex.match(code)}\n",
    "  # uniqify\n",
    "  expanded = list(set(expanded))\n",
    "  return expanded\n",
    "\n",
    "@expand_regex.register(list)\n",
    "def _(code, all_codes):\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_regex(cod, all_codes=all_codes)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = sorted(list(set(expanded)))\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@singledispatch\n",
    "def expand_code(code, all_codes=None,\n",
    "                hyphen=True, star=True, colon=True, regex=False,\n",
    "                drop_dot=False, drop_leading_zero=False,\n",
    "                sort_unique=True, info=None):\n",
    "  raise ValueError('The argument must be a string or a list of strings')\n",
    "\n",
    "@expand_code.register(str)\n",
    "def _(code, all_codes=None,\n",
    "      hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "  #validating input\n",
    "  if (not regex) and (':' in code) and (('-' in code) or ('*' in code)):\n",
    "    raise ValueError('Notation using colon must start from and end in specific codes, not codes using star or hyphen')\n",
    "\n",
    "  if regex:\n",
    "    codes = expand_regex(code, all_codes=all_codes)\n",
    "    return codes\n",
    "\n",
    "  if drop_dot:\n",
    "    code = del_dot(code)\n",
    "\n",
    "  codes=[code]\n",
    "\n",
    "  if hyphen:\n",
    "    codes=expand_hyphen(code)\n",
    "  if star:\n",
    "    codes=expand_star(codes, all_codes=all_codes)\n",
    "  if colon:\n",
    "    codes=expand_colon(codes, all_codes=all_codes)\n",
    "\n",
    "  if sort_unique:\n",
    "    codes = sorted(list(set(codes)))\n",
    "\n",
    "  return codes\n",
    "\n",
    "@expand_code.register(list)\n",
    "def _(code, all_codes=None, hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "\n",
    "  expanded=[]\n",
    "\n",
    "  for cod in code:\n",
    "    new_codes = expand_code(cod, all_codes=all_codes, hyphen=hyphen, star=star, colon=colon, regex=regex, drop_dot=drop_dot, drop_leading_zero=drop_leading_zero)\n",
    "    expanded.extend(new_codes)\n",
    "\n",
    "  # uniqify in case some overlap\n",
    "  expanded = list(set(expanded))\n",
    "\n",
    "  return sorted(expanded)\n",
    "\n",
    "# a dict of names and codes (in a string or a list)\n",
    "@expand_code.register(dict)\n",
    "def _(code, all_codes=None, hyphen=True, star=True, colon=True, regex=False,\n",
    "      drop_dot=False, drop_leading_zero=False,\n",
    "      sort_unique=True, info=None):\n",
    "\n",
    "  expanded={}\n",
    "\n",
    "  for name, cod in code.items():\n",
    "    if isinstance(cod,str):\n",
    "        cod = [cod]\n",
    "    expanded_codes=[]\n",
    "    for co in cod:\n",
    "        new_codes = expand_code(co, all_codes=all_codes, hyphen=hyphen, star=star, colon=colon, regex=regex, drop_dot=drop_dot, drop_leading_zero=drop_leading_zero)\n",
    "        expanded_codes.extend(new_codes)\n",
    "    expanded[name] = list(set(expanded_codes))\n",
    "\n",
    "  return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes={'F3':'F3'}\n",
    "all_codes=['G3', 'F3']\n",
    "expand_code(codes, all_codes=all_codes)\n",
    "cod=[]\n",
    "cod.extend('H3')\n",
    "cod\n",
    "expand_code('F3', all_codes=all_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@singledispatch\n",
    "def expand_columns(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    \"\"\"\n",
    "    Expand columns with special notation to their full column names\n",
    "\n",
    "    \"\"\"\n",
    "    raise ValueError('Must be str or list of str')\n",
    "\n",
    "@expand_columns.register(str)\n",
    "def _(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    notations = '* - :'.split()\n",
    "    # return immediately if not needed\n",
    "    if not any(symbol in expr for symbol in notations):\n",
    "      return [expr]\n",
    "\n",
    "    # get a list of columns of it is only implicity defined by the df\n",
    "    # warning: may depreciate this, require explicit all_columns\n",
    "    if df & (not all_columns):\n",
    "      all_columns=list(df.columns)\n",
    "\n",
    "    if regex:\n",
    "      cols = [col for col in all_columns if re.match(regex, expr)]\n",
    "    else:\n",
    "      if hyphen:\n",
    "        cols = expand_hyphen(expr)\n",
    "      if star:\n",
    "        cols = expand_star(expr, all_codes=all_columns)\n",
    "      if colon:\n",
    "        cols = expand_colon(expr, all_codes=all_columns)\n",
    "\n",
    "    return cols\n",
    "\n",
    "@expand_columns.register(list)\n",
    "def _(expr, all_columns=None, df=None, star=True,\n",
    "                   hyphen=True, colon=True, regex=None, info=None):\n",
    "    all_columns=[]\n",
    "    for col in expr:\n",
    "        new_columns = expand_columns(col, all_columns=all_columns, df=df, star=star,\n",
    "                       hyphen=hyphen, colon=colon, regex=regex, info=info)\n",
    "        all_columns.extend(new_columns)\n",
    "    return all_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More helper functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_codes(codes, merge=True):\n",
    "    \"\"\"\n",
    "    Makes sure that the codes has the desired format: a dict with strings as\n",
    "    keys (name) and a list of codes as values)\n",
    "\n",
    "    Background: For several functions the user is allower to use strings\n",
    "    when there is only one element in the list, and a list when there is\n",
    "    no code replacement or aggregations, or a dict. To avoid (even more) mess\n",
    "    the input is standardised as soon as possible in a function.\n",
    "\n",
    "    Examples:\n",
    "            codes = '4AB02'\n",
    "            codes='4AB*'\n",
    "            codes = ['4AB02', '4AB04', '4AC*']\n",
    "            codes = ['4AB02', '4AB04']\n",
    "            codes = {'tumor' : 'a4*', 'diabetes': ['d3*', 'd5-d9']}\n",
    "            codes = 'S72*'\n",
    "            codes = ['K50*', 'K51*']\n",
    "\n",
    "            _format_codes(codes, merge=False)\n",
    "\n",
    "    TODO: test for correctness of input, not just reformat (is the key a str?)\n",
    "    \"\"\"\n",
    "    codes = _listify(codes)\n",
    "\n",
    "    # treatment of pure lists depends on whether special classes should be treated as one merged group or separate codes\n",
    "    # exmple xounting of Z51* could mean count the total number of codes with Z51 OR a shorthand for saying \"count all codes starting with Z51 separately\n",
    "    # The option \"merged, enables the user to switch between these two interpretations\n",
    "\n",
    "    if isinstance(codes, list):\n",
    "        if merge:\n",
    "            codes = {'_'.join(codes): codes}\n",
    "        else:\n",
    "            codes = {code: [code] for code in codes}\n",
    "\n",
    "    elif isinstance(codes, dict):\n",
    "        new_codes = {}\n",
    "        for name, codelist in codes.items():\n",
    "            if isinstance(codelist, str):\n",
    "                codelist = [codelist]\n",
    "            new_codes[name] = codelist\n",
    "        codes = new_codes\n",
    "\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reverse dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dict(dikt):\n",
    "  \"\"\"\n",
    "  each value in the list of values in the dict become keys in a new dict\n",
    "  \"\"\"\n",
    "  new_dict = {}\n",
    "  for name, codelist in dikt.items():\n",
    "      codelist = listify(codelist)\n",
    "      new_dict.update({code: name for code in codelist})\n",
    "  return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _expand_regex(expr, full_list):\n",
    "    exprs = _listify(expr)\n",
    "\n",
    "    expanded = []\n",
    "\n",
    "    if isinstance(full_list, pd.Series):\n",
    "        pass\n",
    "    elif isinstance(full_list, list):\n",
    "        unique_series = pd.Series(full_list)\n",
    "    elif isinstance(full_list, set):\n",
    "        unique_series = pd.Series(list(full_list))\n",
    "\n",
    "    for expr in exprs:\n",
    "        match = unique_series.str.contains(expr)\n",
    "        expanded.extend(unique_series[match])\n",
    "    return expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persons_with(df,\n",
    "                 codes,\n",
    "                 cols,\n",
    "                 pid='pid',\n",
    "                 sep=None,\n",
    "                 merge=True,\n",
    "                 first_date=None,\n",
    "                 last_date=None,\n",
    "                 group=False,\n",
    "                 _fix=True):\n",
    "    \"\"\"\n",
    "    Determine whether people have received a code\n",
    "\n",
    "    Args:\n",
    "        codes (list or dict): codes to mark for\n",
    "            codes to search for\n",
    "                - if list: each code will represent a column\n",
    "                - if dict: the codes in each item will be aggregated to one indicator\n",
    "            cols (str or list of str): Column(s) with the codes\n",
    "            pid (str): colum with the person identifier\n",
    "            first_date (str): use only codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "            last_date (str): only use codes after a given date\n",
    "                the string either represents a date (same for all individuals)\n",
    "                or the name of a column with dates (may be different for different individuals)\n",
    "\n",
    "    Returns:\n",
    "        Series or Dataframe\n",
    "\n",
    "\n",
    "    Examples:\n",
    "        fracture = persons_with(df=df, codes='S72*', cols='icdmain')\n",
    "        fracture = persons_with(df=df, codes={'frac':'S72*'}, cols='icdmain')\n",
    "\n",
    "    Todo:\n",
    "        - function may check if pid_index is unique, in which it does not have to aggregate\n",
    "        - this may apply in general? functions that work on event data may then also work on person level data\n",
    "        - allow user to input person level dataframe source?\n",
    "    \"\"\"\n",
    "    sub = df\n",
    "\n",
    "    if _fix:\n",
    "        df, cols = _to_df(df=df, cols=cols)\n",
    "        codes, cols, allcodes, sep = _fix_args(df=df, codes=codes, cols=cols, sep=sep, merge=merge, group=group)\n",
    "        rows = get_rows(df=df, codes=allcodes, cols=cols, sep=sep, _fix=False)\n",
    "        sub = df[rows]\n",
    "\n",
    "    df_persons = sub.groupby(pid)[cols].apply(lambda s: pd.unique(s.values.ravel()).tolist()).astype(str)\n",
    "\n",
    "    # alternative approach, also good, and avoids creaintg personal dataframe\n",
    "    # but ... regeis is fast since it stopw when it finds one true code!\n",
    "    #    c=df.icdbi.str.split(', ', expand=True).to_sparse()\n",
    "    #    c.isin(['S720', 'I10']).any(axis=1).any(level=0)\n",
    "\n",
    "    persondf = pd.DataFrame(index=df[pid].unique().tolist())\n",
    "    for name, codes in codes.items():\n",
    "        codes_regex = '|'.join(codes)\n",
    "        persondf[name] = df_persons.str.contains(codes_regex, na=False)\n",
    "\n",
    "    return persondf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formatting an expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## insert_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def insert_external(expr):\n",
    "  \"\"\"\n",
    "  Replaces variables prefixed with @ in the expression with the\n",
    "  value of the variable from the global namespace\n",
    "\n",
    "  Example:\n",
    "      x=['4AB02', '4AB04', '4AB06']\n",
    "      expr = '@x before 4AB02'\n",
    "      insert_external(expr)\n",
    "  \"\"\"\n",
    "  externals = [word.strip('@') for word in expr.split() if word.startswith('@')]\n",
    "  for external in externals:\n",
    "      tmp = globals()[external]\n",
    "      expr = expr.replace(f'@{external} ', f'{tmp} ')\n",
    "  return expr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# A function to identify all unique values in one or more columns\n",
    "# with one or multiple codes in each cell\n",
    "\n",
    "\n",
    "def unique(df, cols=None, sep=None, all_str=True, info=None):\n",
    "  \"\"\"\n",
    "  Lists unique values from one or more columns\n",
    "\n",
    "  sep (str): separator if cells have multiple values\n",
    "  all_str (bool): converts all values to strings\n",
    "\n",
    "  unique(df=df, cols='inpatient', sep=',')\n",
    "  \"\"\"\n",
    "  # if no column(s) are specified, find unique values in whole dataframe\n",
    "  if cols==None:\n",
    "    cols=list(df.columns)\n",
    "  cols = listify(cols)\n",
    "  \n",
    "  # multiple values with separator in cells\n",
    "  if sep:\n",
    "    all_unique=set()\n",
    "    for col in cols:\n",
    "      new_unique = set(df[col].str.cat(sep=',').split(','))\n",
    "      all_unique.update(new_unique)\n",
    "  # single valued cells\n",
    "  else:\n",
    "    all_unique = pd.unique(df[cols].values.ravel('K'))\n",
    "\n",
    "  # if need to make sure all elements are strings without surrounding spaces\n",
    "  if all_str:\n",
    "    all_unique=[str(value).strip() for value in all_unique]\n",
    "\n",
    "  return all_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def count_codes(df, codes=None, cols=None, sep=None, normalize=False,\n",
    "                ascending=False, fix=True, merge=False, group=False, dropna=True, all_codes=None, info=None):\n",
    "    \"\"\"\n",
    "    Count frequency of values in multiple columns and columns with seperators\n",
    "\n",
    "    Args:\n",
    "        codes (str, list of str, dict): codes to be counted. If None, all codes will be counted\n",
    "        cols (str or list of str): columns where codes are\n",
    "        sep (str): separator if multiple codes in cells\n",
    "        merge (bool): If False, each code wil be counted separately\n",
    "            If True (default), each code with special notation will be counted together\n",
    "        strip (bool): strip space before and after code before counting\n",
    "        ignore_case (bool): determine if codes with same characters,\n",
    "            but different cases should be the same\n",
    "        normalize (bool): If True, outputs percentages and not absolute numbers\n",
    "        dropna (bool): If True, codes not listed are not counted and ignored when calculating percentages\n",
    "\n",
    "    allows\n",
    "        - star notation in codes and columns\n",
    "        - values in cells with multiple valules can be separated (if sep is defined)\n",
    "        - replacement and aggregation to larger groups (when code is a dict)\n",
    "\n",
    "    example\n",
    "    To count the number of stereoid events (codes starting with H2) and use of\n",
    "    antibiotics (codes starting with xx) in all columns where the column names\n",
    "    starts with \"atc\":\n",
    "\n",
    "    count_codes(df=df,\n",
    "                 codes={'stereoids' : 'H2*', 'antibiotics' : =['AI3*']},\n",
    "                 cols='atc*',\n",
    "                 sep=',')\n",
    "\n",
    "    more examples\n",
    "    -------------\n",
    "\n",
    "    df.count_codes(codes='K51*', cols='icd', sep=',')\n",
    "    count_codes(df, codes='K51*', cols='icdm', sep=',', group=True)\n",
    "    count_codes(df, codes='Z51*', cols=['icd', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes='Z51*', cols=['icdmain', 'icdbi'], sep=',', group=True)\n",
    "    count_codes(df, codes={'radiation': 'Z51*'}, cols=['icd'], sep=',')\n",
    "    count_codes(df, codes={'radiation': 'Z51*'}, cols=['icdmain', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',')\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=True)\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=False)\n",
    "    count_codes(df, codes={'crohns': 'K50*', 'uc':'K51*'}, cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icd'], sep=',', dropna=False, group=True, merge=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False, merge=False)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=False, group=False, merge=True)\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=True, group=True, merge=True)\n",
    "    #group fasle, merge true, for list = wrong ...\n",
    "\n",
    "    count_codes(df, codes=['K50*', 'K51*'], cols=['icdmain', 'icdbi'], sep=',', dropna=True, group=False, merge=False)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # preliminary formating\n",
    "    if isinstance(df, pd.Series):\n",
    "      df=df.to_frame()\n",
    "      cols=list(df.columns)\n",
    "      # maybe df[pid]=df.index\n",
    "\n",
    "    if not codes:\n",
    "      codes=unique(df=df, cols=cols, sep=sep, info=info)\n",
    "      all_codes = list(set(codes))\n",
    "    \n",
    "    cols=expand_columns(cols, all_columns=list(df.columns))\n",
    "    \n",
    "    if not all_codes:\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep)\n",
    "    \n",
    "    old_codes=codes\n",
    "    \n",
    "    codes = expand_code(codes, all_codes=all_codes, info=info)\n",
    "\n",
    "    if isinstance(old_codes, str) and (merge):\n",
    "      codes = {old_codes:codes}\n",
    "    elif isinstance(old_codes, str) and not (merge):\n",
    "      codes = {code:code for code in codes}\n",
    "    elif isinstance(old_codes, list) and (merge):\n",
    "      codes = {str(old_codes): codes}\n",
    "    elif isinstance(old_codes, list) and not (merge):\n",
    "      codes = {code: code for code in codes}\n",
    "    \n",
    "    only_codes=[]\n",
    "    for name, code in codes.items():\n",
    "        code=listify(code)\n",
    "        only_codes.extend(code)\n",
    "        # prevent duplicates\n",
    "        only_codes=list(set(only_codes))\n",
    "        \n",
    "    sub = df\n",
    "    \n",
    "    if dropna:\n",
    "        rows = get_rows(df=sub, codes=only_codes, cols=cols, sep=sep, all_codes=all_codes)\n",
    "        sub = sub[rows]\n",
    "\n",
    "    if sep:\n",
    "      count=Counter()\n",
    "      for col in cols:\n",
    "        codes_in_col = [code.strip() for code in sub[col].str.cat(sep=sep).split(sep)]\n",
    "        count.update(codes_in_col)\n",
    "      code_count=pd.Series(count)\n",
    "    else:\n",
    "        code_count = sub[cols].apply(pd.Series.value_counts).sum(axis=1)\n",
    "\n",
    "    if codes:\n",
    "        not_included_n = code_count[~code_count.isin(only_codes)].sum()\n",
    "        code_count = code_count[only_codes]\n",
    "        if not dropna:\n",
    "            code_count['na'] = not_included_n\n",
    "\n",
    "    if isinstance(codes, dict):\n",
    "        code_count = code_count.rename(index=reverse_dict(codes)).sum(level=0)\n",
    "\n",
    "    if normalize:\n",
    "        code_n = code_count.sum()\n",
    "        code_count = code_count / code_n\n",
    "    else:\n",
    "        code_count = code_count.astype(int)\n",
    "\n",
    "    if ascending:\n",
    "        code_count = code_count.sort_values(ascending=True)\n",
    "    else:\n",
    "        code_count = code_count.sort_values(ascending=False)\n",
    "\n",
    "    return code_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>gender</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1949-02-19</td>\n",
       "      <td>1959-11-04</td>\n",
       "      <td>east</td>\n",
       "      <td>V42,O16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1950-10-05</td>\n",
       "      <td>1952-07-13</td>\n",
       "      <td>south</td>\n",
       "      <td>J89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1950-10-05</td>\n",
       "      <td>1953-06-19</td>\n",
       "      <td>south</td>\n",
       "      <td>S87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1950-10-05</td>\n",
       "      <td>1956-01-30</td>\n",
       "      <td>south</td>\n",
       "      <td>J88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>1950-10-05</td>\n",
       "      <td>1956-04-25</td>\n",
       "      <td>south</td>\n",
       "      <td>T6,P14,B35,W83,Q5,K94,R63,Z16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  gender birth_date       date region                          codes\n",
       "1    1  female 1949-02-19 1959-11-04   east                        V42,O16\n",
       "2    2    male 1950-10-05 1952-07-13  south                            J89\n",
       "2    2    male 1950-10-05 1953-06-19  south                            S87\n",
       "2    2    male 1950-10-05 1956-01-30  south                            J88\n",
       "2    2    male 1950-10-05 1956-04-25  south  T6,P14,B35,W83,Q5,K94,R63,Z16"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=make_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_codes(df=df, codes={'a':['G4*', 'C4*', 'c4'], 'b':'A4*'}, cols='codes', sep=',', merge=True, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid  gender birth_date       date region                          codes\n",
      "1    1  female 1949-02-19 1959-11-04   east                        V42,O16\n",
      "2    2    male 1950-10-05 1952-07-13  south                            J89\n",
      "2    2    male 1950-10-05 1953-06-19  south                            S87\n",
      "2    2    male 1950-10-05 1956-01-30  south                            J88\n",
      "2    2    male 1950-10-05 1956-04-25  south  T6,P14,B35,W83,Q5,K94,R63,Z16 cols codes\n",
      "{'A4': 'A4', 'A40': 'A40', 'A41': 'A41', 'A42': 'A42', 'A43': 'A43', 'A44': 'A44', 'A45': 'A45', 'A46': 'A46', 'A47': 'A47', 'A48': 'A48', 'A49': 'A49'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "A4     12\n",
       "A48    10\n",
       "A46     9\n",
       "A47     9\n",
       "A44     8\n",
       "A43     8\n",
       "A40     7\n",
       "A42     7\n",
       "A41     6\n",
       "A49     5\n",
       "A45     5\n",
       "dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_codes(df=df, codes='A4*', cols='codes', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "G32    27\n",
       "G14    25\n",
       "G31    25\n",
       "G41    23\n",
       "G81    23\n",
       "       ..\n",
       "E65     1\n",
       "H85     1\n",
       "T4      1\n",
       "M61     1\n",
       "J67     1\n",
       "Length: 2573, dtype: int32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.hrr3.count_codes(codes='A*', cols='codes', sep=',')\n",
    "df.codes.hrrb.count_codes(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.codes.hrrb.count_codes(sep=',',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a', 'b']\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lookup_codes(dikt, codes):\n",
    "    \"\"\"\n",
    "    returns those elements in a dict where key starts with the expressions listed in codes\n",
    "\n",
    "    todo: more complicated star notations: starts with, contains, endswith\n",
    "    lookup(medcodes, 'L04*')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    codes = _listify(codes)\n",
    "    codes = [code.upper().strip('*') for code in codes]\n",
    "    codes = tuple(codes)\n",
    "\n",
    "    selected_codes = {k: v for k, v in dikt.items() if str(k).upper().startswith(codes)}\n",
    "    return selected_codes\n",
    "\n",
    "\n",
    "# %%\n",
    "def get_codes(dikt, text):\n",
    "    \"\"\"\n",
    "    returns those elements in a dict where value contains the expressions listed in codes\n",
    "\n",
    "    todo: more complicated star notations: starts with, contains, endswith\n",
    "    alterative name: find_codes? get_codes?\n",
    "\n",
    "    example\n",
    "    get all codes that have \"steroid\" in the explanatory text\n",
    "\n",
    "        get_codes(medcodes, 'steroid*')\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text = _listify(text)\n",
    "    text = [txt.upper().strip('*') for txt in text]\n",
    "    # codes = \" \".join(codes)\n",
    "\n",
    "    selected_codes = {k: v for k, v in dikt.items() if any(txt in str(v).upper() for txt in text)}\n",
    "\n",
    "    return selected_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd.api.extensions.register_dataframe_accessor(\"hrr6\")\n",
    "class RegisterResearchAccessor:\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "\n",
    "    def count_codes(df, codes=None, cols=None, sep=None, normalize=False,\n",
    "                ascending=False, fix=True, merge=False, group=False, dropna=True, all_codes=None, info=None):\n",
    "        df=df._df\n",
    "        result = count_codes(df=df, codes=codes, cols=cols, sep=sep, normalize=normalize,\n",
    "                ascending=ascending, fix=fix, merge=merge, dropna=dropna, all_codes=all_codes, info=info)\n",
    "        return result\n",
    "      \n",
    "    \n",
    "@pd.api.extensions.register_series_accessor(\"hrr6\")\n",
    "class RegisterResearchAccessor:\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "    \n",
    "    def count_codes(df, codes=None, cols=None, sep=None, normalize=False,\n",
    "                ascending=False, fix=True, merge=False, group=False, dropna=True, all_codes=None, info=None):\n",
    "        df=df._df\n",
    "        result = count_codes(df=df, codes=codes, cols=cols, sep=sep, normalize=normalize,\n",
    "                ascending=ascending, fix=fix, merge=merge, dropna=dropna, all_codes=all_codes, info=info)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "@pd.api.extensions.register_series_accessor(\"hrrb\")\n",
    "class RegisterResearchAccessorSeries:\n",
    "    def __init__(self, df):\n",
    "        self._df = df\n",
    "        \n",
    "    def count_codes(df, **kwargs):\n",
    "        df=df._df\n",
    "        kwargs.update(df=df)\n",
    "        result = count_codes(**kwargs)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nbdev.sync import script2notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1_intro_make_data_notation.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted old_functions.ipynb.\n",
      "Converted pattern_finder.ipynb.\n",
      "Converted utilities.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
