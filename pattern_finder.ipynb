{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pattern_finder.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pattern finder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sankey format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sankey_format(df, labels=None, normalize=False, dropna=False, threshold=0.01):\n",
    "    \"\"\"\n",
    "    Format the dataframe so it is easy fo create a holoviews sankey figure\n",
    "\n",
    "    labels=dict(bio_codes.values())\n",
    "    import holoviews as hv\n",
    "    hv.Sankey(t1).options(label_position='left')\n",
    "    hv.extension('bokeh')\n",
    "    t4=t1.copy()\n",
    "\n",
    "    \"\"\"\n",
    "    a = df\n",
    "    a = a.apply(lambda row: ' '.join(row))\n",
    "    a = a.str.split(expand=True)\n",
    "\n",
    "    a = a.replace(labels)\n",
    "    for col in a.columns:\n",
    "        a[col] = a[col] + ' (' + str(col + 1) + ')'\n",
    "\n",
    "\n",
    "    if not dropna:\n",
    "        a = a.fillna(f'No new')\n",
    "\n",
    "    all_counts = {}\n",
    "    for col in range(len(a.columns))[1:]:\n",
    "        counts = a.groupby(a[col - 1])[col].value_counts(normalize=normalize)\n",
    "        if normalize:\n",
    "            counts = counts.mul(100).astype(int).fillna(0)\n",
    "\n",
    "        counts.name = 'value'\n",
    "        # counts = counts.rename(index=labels).reset_index()\n",
    "        counts = counts.reset_index()\n",
    "        counts.columns = ['source', 'target', 'value']\n",
    "\n",
    "        all_counts[col] = counts\n",
    "    t1 = pd.concat(all_counts, ignore_index=True)\n",
    "\n",
    "    #if normalize:\n",
    "    #    t1['value'] = t1['value'] / t1['value'].sum()\n",
    "\n",
    "    t1 = t1[t1.source != 'No new']\n",
    "\n",
    "    # a.groupby(1)[2].value_counts()\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "df=make_data(letters=5, numbers=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = {'a':'A4', 'b':'B2', 'c':'C1'}\n",
    "order = stringify_order(df=df, codes=codes, cols='codes', sep=',', keep_repeats=False, only_unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorder=sankey_format(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "\n",
    "#hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('matplotlib')\n",
    "hv.output(fig='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey = hv.Sankey(sorder, label='Energy Diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sankey = hv.Sankey(sorder, label='Energy Diagram')\n",
    "sankey.opts(label_position='left', edge_color='source', node_color='source', cmap='tab20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stringify durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stringify_durations(df,\n",
    "                        codes=None,\n",
    "                        cols=None,\n",
    "                        pid='pid',\n",
    "                        step=120,\n",
    "                        sep=None,\n",
    "\n",
    "                        event_start='in_date',\n",
    "                        event_end=None,\n",
    "                        event_duration='ddd',\n",
    "\n",
    "                        first_date=None,\n",
    "                        last_date=None,\n",
    "                        censored_date=None,\n",
    "\n",
    "                        ncodes=None,\n",
    "\n",
    "                        no_event='-',\n",
    "                        time_sep='|',\n",
    "\n",
    "                        merge=True,\n",
    "                        info=None,\n",
    "                        report=False,\n",
    "                        all_codes=None):\n",
    "    \"\"\"\n",
    "    Creates a string for each individual describing the time duration selected code events (example: a-, ad, --, a)\n",
    "\n",
    "    Args:\n",
    "        df: dataframe\n",
    "        codes: codes to be used to mark an event\n",
    "        cols: columns with the event codes\n",
    "        pid: column with the personal identification number\n",
    "        event_start: column containing the date for the event\n",
    "        sep: the separator used between events if a column has multiple events in a cell\n",
    "        keep_repeats: identical events after each other are reduced to one (if true)\n",
    "        only_unique: deletes all events that have occurred previously for the individual (if true)\n",
    "\n",
    "    Returns:\n",
    "        series with a string that describes the events for each individual\n",
    "    Example:\n",
    "\n",
    "    >>> codes={'i' : ['4AB02', 'L04AB02'], 'a': ['4AB04','L04AB04']}\n",
    "    >>> events=sa.stringify_durations(df=mdf, codes=codes, cols='codes',\n",
    "    event_start='date', first_date=None, sep=',', merge=True)\n",
    "\n",
    "    >>> codes={'i' : ['4AB02', 'L04AB02'], 'a': ['4AB04','L04AB04']}\n",
    "    >>> codes={'i' : ['L04*'], 'b': ['4AB04','L04AB04']}\n",
    "\n",
    "\n",
    "    >>> codes = {'i':'L01BB02 L04AX03 L01BA01 L04AD01 L04AD02 L04AA06'.split(),\n",
    "                 'b':'L04AB02 L04AB04 L04AB06 L04AA33 L04AC05 L04AA23'.split()}\n",
    "\n",
    "\n",
    "    >>> events=sa.stringify_durations(df=mdf, codes=codes, cols='codes',\n",
    "    event_start='date', first_date=None, sep=',', merge=False, step=100)\n",
    "\n",
    "    >>> codes={'L04A*' : 'i', 'L04AB*' : 'a', 'H02*' : 'c'}\n",
    "    >>> pr=pr.set_index('pid_index')\n",
    "    >>> pr['first_date'] = pr.groupby('pid')['date'].min()\n",
    "    >>> events=stringify_durations(df=df, codes=codes, col='ncmpalt', start='start_date', first_date='first', dataset_end_date=\"01-01-2018\")\n",
    "\n",
    "\n",
    "    background\n",
    "        to identify treatment patters, first stringify each treatment,\n",
    "        then aggregate the different treatments to one string\n",
    "        each \"cell\" in the string (separated by sep) represent one time unit\n",
    "        the time unit can be further aggregated to reduce the level of detail\n",
    "\n",
    "    example output (one such row for each person)\n",
    "        a---s, a---, ai-s, a---, ----\n",
    "\n",
    "        Interpretation: A person with event a and s in first time perod, then a only in second,\n",
    "        the a, i and s in the third, a only in fourth and no events in the last\n",
    "\n",
    "    purpose\n",
    "        examine typical treatment patterns and correlations\n",
    "        use regex or other string operations on this to get statistcs\n",
    "        (time on first line of treatment, number of switches, stops)\n",
    "\n",
    "    \"\"\"\n",
    "    # drop rows with missing observations in required variable\n",
    "        \n",
    "    df = df.dropna(subset=[pid, event_start])\n",
    "\n",
    "    if event_end:\n",
    "        df = df.dropna(subset=[event_end])\n",
    "    elif event_duration:\n",
    "        df = df.dropna(subset=[event_duration])\n",
    "        if df[event_duration].min() < 0:\n",
    "            print('Error: The specified duration column contains negative values. They are dropped')\n",
    "            df = df[df[event_duration] >= 0]\n",
    "    else:\n",
    "        print('Error: Either event_end or event_duration has to be specified.')\n",
    "\n",
    "    # find default min and max dates\n",
    "    # will be used as starting points for the string\n",
    "    # if first_date and last_date are not specified\n",
    "    min_date = df[event_start].min()\n",
    "    max_date = df[event_start].max()\n",
    "\n",
    "    # drop rows outside specified time period of interest\n",
    "    if first_date:\n",
    "        if first_date in df.columns:\n",
    "            df = df[df[event_start] >= df[first_date]]\n",
    "        elif isinstance(first_date, dict):\n",
    "            pass\n",
    "        else:\n",
    "            # if first_date is not a column name, it is assumed to be a date\n",
    "            try:\n",
    "                min_date = pd.to_datetime(first_date)\n",
    "                df = df[df[event_start] >= min_date]\n",
    "            except:\n",
    "                print('Error: The first_date argument has to be on of: None, a dict, a column name or a string that represents a date')\n",
    "\n",
    "    if last_date:\n",
    "        if last_date in df.columns:\n",
    "            df = df[df[event_start] >= df[last_date]]\n",
    "        elif isinstance(last_date, dict):\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                max_date = pd.to_datetime(last_date)\n",
    "                df = df[df[event_start] <= max_date]\n",
    "            except:\n",
    "                print('Error: The last_date argument has to be on of: None, a dict, a column name or a string the represents a date')\n",
    "\n",
    "    # note an individual min date cannot be before overall specified min date\n",
    "    # should raise error if user tries this\n",
    "    # same with max: individual cannot be larger than overall\n",
    "\n",
    "    max_length_days = (max_date - min_date).days\n",
    "    max_length_steps = int(max_length_days / step)\n",
    "\n",
    "    # # if codes are not specified, use the five most common codes\n",
    "    # if not codes:\n",
    "    #     cols = _expand_cols(_listify(cols))\n",
    "    #     if not ncodes: ncodes = 4\n",
    "    #     codes = count_codes(df=df, cols=cols, sep=sep).sort_values(ascending=False)[:ncodes]\n",
    "\n",
    "    # fix formatting of input (make list out of a string input and so on)\n",
    "    cols=expand_columns(cols, all_columns=list(df.columns))\n",
    "    \n",
    "    if not all_codes:\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep)\n",
    "    codes = expand_code(codes, all_codes=all_codes, info=info)\n",
    "    \n",
    "\n",
    "    only_codes=[]\n",
    "    for name, code in codes.items():\n",
    "        only_codes.extend(code)\n",
    "    print('only_codes', only_codes)\n",
    "    \n",
    "    # get the rows that contain the relevant codes\n",
    "    rows = get_rows(df=df, codes=only_codes, cols=cols, sep=sep, fix=False)\n",
    "    subset = df[rows].copy()  # maybe use .copy to avoid warnings? but takes time and memory\n",
    "    subset = subset.set_index(pid, drop=False)\n",
    "    subset.index.name = 'pid_index'\n",
    "    subset = subset.sort_values([pid, event_start])\n",
    "\n",
    "    if report:\n",
    "        sub_obs = len(subset)\n",
    "        sub_npid = subset[pid].nunique()\n",
    "\n",
    "    # find start and end position of each event (number of steps from overall min_date)\n",
    "    # to do: do not use those column names (may overwrite original names), use uuid names?\n",
    "    subset['start_position'] = (subset[event_start] - min_date).dt.days.div(step).astype(int)\n",
    "\n",
    "    if event_end:\n",
    "        subset['end_position'] = (subset[event_end] - min_date).dt.days.div(step).astype(int)\n",
    "    elif event_duration:\n",
    "        subset['end_date'] = subset[event_start] + pd.to_timedelta(subset[event_duration].astype(int), unit='D')\n",
    "        subset['end_position'] = (subset['end_date'] - min_date).dt.days.div(step).astype(int)\n",
    "\n",
    "    # to do: may allow duration dict?\n",
    "    # for instance: some drugs last 15 days, some drugs last 25 days . all specified in a dict\n",
    "\n",
    "    # create series with only the relevant codes for each person and position\n",
    "    code_series = extract_codes(df=subset.set_index([pid, 'start_position', 'end_position']),\n",
    "                                codes=codes,\n",
    "                                cols=cols,\n",
    "                                sep=sep,\n",
    "                                new_sep=',',\n",
    "                                merge=False,\n",
    "                                out='text',\n",
    "                                all_codes=all_codes,\n",
    "                                fix=False)\n",
    "\n",
    "    unique_codes = list(code_series.columns)\n",
    "\n",
    "    code_series = pd.melt(code_series.reset_index(),\n",
    "                          id_vars=['pid', 'start_position', 'end_position'],\n",
    "                          value_vars=unique_codes)\n",
    "\n",
    "    # drop duplicates (same type of even in same period for same individual)\n",
    "    code_series = code_series.drop_duplicates().set_index(pid, drop=False)\n",
    "    code_series.index.name = 'pid_index'\n",
    "    ## make dict with string start and end positions for each individual\n",
    "    # explanation:\n",
    "    # the string is first made marking events in positions using calendar time\n",
    "    # but often we want the end result to be strings that start at specified\n",
    "    # individual dates, and not the same calendar date for all\n",
    "    # for instance it is often useful to start the string at the date the\n",
    "    # person receives a diagnosis\n",
    "    # same with end of string: strings may end when a patient dies\n",
    "    # user can specify start and end dates by pointing to columns with dates\n",
    "    # or they may specify an overall start and end date\n",
    "    # if individual dates are specified, the long string based on calendar\n",
    "    # time is sliced to include only the relevant events\n",
    "\n",
    "    if first_date:\n",
    "        # if a column is specified\n",
    "        if first_date in subset.columns:\n",
    "            start_date = subset.groupby(pid)[first_date].first().dropna().to_dict()\n",
    "        # do nothing if a dict mapping pids to last_dates is already specified\n",
    "        elif isinstance(first_date, dict):\n",
    "            pass\n",
    "        # if a single overall date is specified\n",
    "        else:\n",
    "            date = pd.to_datetime(first_date)\n",
    "            start_date = {pid: date for pid in subset[pid].unique()}\n",
    "        # convert start date to start position in string\n",
    "        string_start_position = {pid: int((date - min_date).days / step)\n",
    "                                 for pid, date in start_date.items()}\n",
    "\n",
    "    if last_date:\n",
    "        if last_date in subset:\n",
    "            end_date = subset.groupby(pid)[last_date].first().dropna().to_dict()\n",
    "        # do nothing if a dict mapping pids to last_dates is already specified\n",
    "        elif isinstance(last_date, dict):\n",
    "            pass\n",
    "        else:\n",
    "            date = pd.to_datetime(last_date)\n",
    "            end_date = {pid: date for pid in subset[pid].unique()}\n",
    "        # convert date to position in string\n",
    "        string_end_position = {pid: int(((date - min_date).days)/step)\n",
    "                               for pid, date in end_date.items()}\n",
    "\n",
    "        # takes dataframe for an individual and makes a string with the events\n",
    "\n",
    "    def make_string(events, code):\n",
    "        # get pid of individual (required to find correct start and end point)\n",
    "        person = events.index[0]\n",
    "\n",
    "        # make a list of maximal length with no events\n",
    "        event_list = [no_event] * (max_length_steps + 1)\n",
    "\n",
    "        from_to_positions = tuple(zip(events['start_position'].tolist(), events['end_position'].tolist()))\n",
    "\n",
    "        # loop over all events the individual has and put code in correct pos.\n",
    "        for pos in from_to_positions:\n",
    "            length=pos[1]-pos[0]\n",
    "            event_list[pos[0]:pos[1]] = [code]*length\n",
    "        event_string = \"\".join(event_list)\n",
    "\n",
    "        # slice to correct start and end of string (if specified)\n",
    "        # if first_date:\n",
    "        #     event_string = event_string[string_start_position[person]:]\n",
    "        # if last_date:\n",
    "        #     max_position = int((max_date - min_date).days / step)\n",
    "        event_string = event_string[string_start_position[person] : string_end_position[person]+1]\n",
    "        return event_string\n",
    "\n",
    "    # new dataframe to store each string for each individual for each code\n",
    "    string_df = pd.DataFrame(index=code_series[pid].unique())\n",
    "    string_df.index.name = 'pid_index'\n",
    "\n",
    "    # loop over each code, aggregate strong for each individual, store in df\n",
    "    for code in unique_codes:\n",
    "        code_df = code_series[code_series['value'].isin([code])] # maybe == is better (safer bco compounds + faster?)\n",
    "        stringified = code_df.groupby(pid, sort=False).apply(make_string, code)\n",
    "        string_df[code] = stringified\n",
    "\n",
    "    if merge:\n",
    "        string_df = interleave_strings(string_df, no_event=no_event, time_sep=time_sep)\n",
    "\n",
    "    if report:\n",
    "        final_obs = len(subset)\n",
    "        final_npid = len(string_df)\n",
    "        print(f\"\"\"\n",
    "                                     events,  unique ids\n",
    "              Original dataframe     {obs}, {npid} \n",
    "              Filter codes           {code_obs}, {code_npid}\n",
    "              Filter missing         {sub_obs}, {sub_npid}\n",
    "              Final result:          {final_obs}, {final_npid}\"\"\")\n",
    "    return string_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _make_binary(df, cols=None, no_event=' ', time_sep='|', pad=False):\n",
    "    if isinstance(df, pd.Series):\n",
    "        name = df[col].name\n",
    "        df=df.str.replace(no_event, '0')\n",
    "        df=df.str.replace(name, '1')\n",
    "    else:\n",
    "        # if no cols are selected, use all cols\n",
    "        if not cols:\n",
    "            cols = list(df.columns)\n",
    "        # replace event chars with 1 and no events with 0\n",
    "        for col in cols:\n",
    "            name = df[col].name\n",
    "            df[col]=df[col].str.replace(no_event, '0')\n",
    "            df[col]=df[col].str.replace(name, '1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def interleave_strings(df, cols=None, time_sep=\"|\", no_event=' ', agg=False):\n",
    "    \"\"\"\n",
    "    Interleaves strings in two or more columns\n",
    "\n",
    "    parameters\n",
    "        cols : list of columns with strings to be interleaved\n",
    "        nan : value to be used in place of missing values\n",
    "        sep : seperator to be used between time periods\n",
    "        agg : numeric, used to indicate aggregation of time scale\n",
    "                default is 1\n",
    "\n",
    "    background\n",
    "        to identify treatment patters, first stringify each treatment,\n",
    "        then aggregate the different treatments to one string\n",
    "        each \"cell\" in the string (separated by sep) represent one time unit\n",
    "        the time unit can be further aggregated to reduce the level of detail\n",
    "\n",
    "    example output (one such row for each person)\n",
    "        a---s, a---, ai-s, a---, ----\n",
    "\n",
    "        Interpretation: A person with event a and s in first time perod, then a only in second,\n",
    "        the a, i and s in the third, a only in fourth and no events in the last\n",
    "\n",
    "    purpose\n",
    "        examine typical treatment patterns and correlations\n",
    "        use regex or other string operations on this to get statistcs\n",
    "        (time on first line of treatment, number of switches, stops)\n",
    "\n",
    "    \"\"\"\n",
    "    # if cols is not specified, use all columns in dataframe\n",
    "    if not cols:\n",
    "        cols = list(df.columns)\n",
    "\n",
    "    if agg:\n",
    "        for col in cols:\n",
    "            df[col] = df[col].fillna(no_event)\n",
    "            # find event symbol, imply check if all are missing, no events\n",
    "            try:\n",
    "                char = df[col].str.cat().strip().str.strip('-')[0]  # improvable?\n",
    "            except:\n",
    "                df[col] = (col.str.len() / agg) * no_event\n",
    "\n",
    "            def aggregator(text, agg):\n",
    "                missing = no_event * agg\n",
    "                units = (text[i:i + agg] for i in range(0, len(text), agg))\n",
    "                new_aggregated = (no_event if unit == missing else char for unit in units)\n",
    "                new_str = \"\".join(new_aggregated)\n",
    "                return new_str\n",
    "        df[col] = df[col].apply(aggregator, agg=agg)\n",
    "\n",
    "    if time_sep:\n",
    "        interleaved = df[cols].fillna(no_event).apply(\n",
    "            (lambda x: time_sep.join(\n",
    "                \"\".join(i)\n",
    "                for i in zip_longest(*x, fillvalue=no_event))),\n",
    "            axis=1)\n",
    "    else:\n",
    "        interleaved = df[cols].fillna('-').apply(\n",
    "            (lambda x: \"\".join(chain(*zip_longest(*x, fillvalue=no_event)))),\n",
    "            axis=1)\n",
    "\n",
    "    return interleaved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## left justify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def left_justify(s, fill=' '):\n",
    "    \"\"\"\n",
    "    after stringify, to make events at same time be in same position\n",
    "    and no, not as crucial as left-pad!\n",
    "    \"\"\"\n",
    "    nmax = s.apply(len).max()\n",
    "    s = s.str.pad(width=nmax, side='right', fillchar=fill)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overlay strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def overlay_strings(df, cols=None, sep=\",\", nan='-', collisions='x', interleaved=False):\n",
    "    \"\"\"\n",
    "    overlays strings from two or more columns\n",
    "\n",
    "    note\n",
    "        most useful when aggregating a string for events that usually do not happen in the same time frame\n",
    "\n",
    "    parameters\n",
    "        cols : list of columns with strings to be interleaved\n",
    "        nan : value to be used in place of missing values\n",
    "        collisions: value to be used if there is a collision between events in a position\n",
    "\n",
    "\n",
    "    background\n",
    "        to identify treatment patters, first stringify each treatment,\n",
    "        then aggregate the different treatments to one string\n",
    "        each \"cell\" in the string (separated by sep) represent one time unit\n",
    "        the time unit can be further aggregated to reduce the level of detail\n",
    "\n",
    "    example output (one such row for each person)\n",
    "        asaaa--s--aa-s-a\n",
    "\n",
    "        Interpretation: A person with event a and s in first time perod, then a only in second,\n",
    "        the a, i and s in the third, a only in fourth and no events in the last\n",
    "\n",
    "    purpose\n",
    "        examine typical treatment patterns and correlations\n",
    "        use regex or other string operations on this to get statistcs\n",
    "        (time on first line of treatment, number of switches, stops)\n",
    "\n",
    "    todo\n",
    "        more advanced handling of collisions\n",
    "            - special symbols for different types of collisions\n",
    "            - warnings (and keep/give info on amount and type of collisions)\n",
    "\n",
    "    \"\"\"\n",
    "    # if cols is not specified, use all columns in dataframe\n",
    "    if not cols:\n",
    "        cols = list(df.columns)\n",
    "\n",
    "    interleaved = df[cols].fillna('-').apply(\n",
    "        (lambda x: \"\".join(chain(*zip_longest(*x, fillvalue='-')))),\n",
    "        axis=1)\n",
    "    step_length = len(cols)\n",
    "\n",
    "    def event_or_collision(events):\n",
    "        try:\n",
    "            char = events.strip('-')[0]\n",
    "        except:\n",
    "            char = '-'\n",
    "        n = len(set(events).remove('-'))\n",
    "        if n > 1:\n",
    "            char = 'x'\n",
    "        return char\n",
    "\n",
    "    def overlay_individuals(events):\n",
    "\n",
    "        units = (events[i:i + step_length] for i in range(0, len(events), step_length))\n",
    "\n",
    "        new_aggregated = (event_or_collision(unit) for unit in units)\n",
    "        new_str = \"\".join(new_aggregated)\n",
    "        return new_str\n",
    "\n",
    "    interleaved.apply(overlay_individuals)\n",
    "\n",
    "    return interleaved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shorten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def shorten(events, agg=3, no_event=' '):\n",
    "    \"\"\"\n",
    "    create a new and shorter string with a longer time step\n",
    "\n",
    "    parameters\n",
    "        events: (str) string of events that will be aggregated\n",
    "        agg: (int) the level of aggregation (2=double the step_length, 3=triple)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        char = events.strip(no_event)[0]\n",
    "    except:\n",
    "        char = no_event\n",
    "    units = (events[i:i + agg] for i in range(0, len(events), agg))\n",
    "    new_aggregated = (no_event if unit == no_event else char for unit in units)\n",
    "    new_str = \"\".join(new_aggregated)\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shorten_interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def shorten_interleaved(text, agg=3, time_sep=',', no_event=' '):\n",
    "    \"\"\"\n",
    "    text=\"a-si,a--i,a-s-,--si,---i,--s-\"\n",
    "\n",
    "    shorten_interleaved(c, agg=2)\n",
    "\n",
    "    the original string must have a distinction between time_sep and no_event_sep\n",
    "    (if not, could try to infer)\n",
    "    \"\"\"\n",
    "    units = text.split(time_sep)\n",
    "    ncodes = len(units[0])\n",
    "    nunits = len(units)\n",
    "\n",
    "    unitlist = [units[i:i + agg] for i in range(0, nunits, agg)]\n",
    "    charlist = [\"\".join(aggunit) for aggunit in unitlist]\n",
    "    unique_char = [\"\".join(set(chain(chars))) for chars in charlist]\n",
    "    new_str = time_sep.join(unique_char)\n",
    "    # ordered or sorted?\n",
    "    # delete last if it is not full ie. not as many timee units in it as the others?\n",
    "    # shortcut for all\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stringify order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stringify_order(df, codes=None, cols=None, pid='pid', event_start='date',\n",
    "                    sep=None, time_sep='', first_date=None, last_date=None, period=None, keep_repeats=True,\n",
    "                    only_unique=False, fix=True):\n",
    "    \"\"\"\n",
    "    Creates a string for each individual describing selected code events in the order they occurred\n",
    "\n",
    "    Args:\n",
    "        df: dataframe\n",
    "        codes: codes to be used to mark an event\n",
    "        cols: columns with the event codes\n",
    "        pid: column with the personal identification number\n",
    "        event_start: column containing the date for the event\n",
    "        sep: the separator used between events if a column has multiple events in a cell\n",
    "        keep_repeats: identical events after each other are reduced to one (if true)\n",
    "        only_unique: deletes all events that have occurred previously for the individual (if true)\n",
    "\n",
    "    Returns:\n",
    "        series with a string that describes the events for each individual\n",
    "\n",
    "\n",
    "\n",
    "    Examples:\n",
    "\n",
    "    >>> bio_codes= {'L04AA23': 'n', 'L04AA33': 'v', 'L04AB02': 'i', 'L04AB04': 'a','L04AB06': 'g', 'L04AC05': 'u'}\n",
    "\n",
    "    >>> bio_codes={'e' : '4AB01', 'i' : '4AB02', 'a' : '4AB04'}\n",
    "\n",
    "    >>> bio_codes={'i' : '4AB02', 'a' : '4AB04'}\n",
    "\n",
    "    >>> bio_codes= {'n': ['L04AA23', '4AA23'],\n",
    "                    'v': ['L04AA33', '4AA33'],\n",
    "                    'i': ['L04AB02', '4AB02'],\n",
    "                    'a': ['L04AB04', '4AB04'],\n",
    "                    'g': ['L04AB06', '4AB06'],\n",
    "                    'u': ['L04AC05', '4AC05']}\n",
    "\n",
    "\n",
    "    >>> a=stringify_order(df=df, codes=bio_codes, cols='ncmpalt', pid='pid', event_start='start_date', sep=',', keep_repeats=True, only_unique=False)\n",
    "\n",
    "    >>> a=sa.stringify_order(df=mdf, codes=bio_codes, cols='codes', pid='pid', first_date='first_ibd',\n",
    "    event_start='date', sep=',', keep_repeats=False, only_unique=False, time_sep='', period=700)\n",
    "\n",
    "\n",
    "    >>> bio_rows=get_rows(df=pr, codes=list(codes.keys()), cols='atc')\n",
    "    >>> pr['first_bio']=pr[bio_rows].groupby('pid')['date'].min()\n",
    "\n",
    "    >>> stringify_order(df=pr, codes=codes, cols='atc', pid='pid', event_date='date', sep=',')\n",
    "\n",
    "    >>> stringify_order(df=pr, codes=bio_codes, cols='codes', pid='pid', event_date='date', sep=',')\n",
    "\n",
    "\n",
    "    background\n",
    "        to identify treatment patters, first stringify each treatment,\n",
    "        then aggregate the different treatments to one string\n",
    "        each \"cell\" in the string (separated by sep) represent one time unit\n",
    "        the time unit can be further aggregated to reduce the level of detail\n",
    "\n",
    "    example output (one such row for each person)\n",
    "        a---s, a---, ai-s, a---, ----\n",
    "\n",
    "        Interpretation: A person with event a and s in first time perod, then a only in second,\n",
    "        the a, i and s in the third, a only in fourth and no events in the last\n",
    "\n",
    "    purpose\n",
    "        examine typical treatment patterns and correlations\n",
    "        use regex or other string operations on this to get statistcs\n",
    "        (time on first line of treatment, number of switches, stops)\n",
    "    \"\"\"\n",
    "    print('no3')\n",
    "    df.index.name = 'pid_index'  # avoid errors, and yes, require pid to be in index (?)\n",
    "\n",
    "    df = df.dropna(subset=[pid, event_start])\n",
    "\n",
    "    # example only include events after first diagnosis\n",
    "    if first_date:\n",
    "        df = df.dropna(subset=[first_date])\n",
    "\n",
    "        # if a column is specified\n",
    "        if first_date in df.columns:\n",
    "            include = (df[event_start] >= df[first_date])\n",
    "            # if a single overall date is specified\n",
    "        else:\n",
    "            date = pd.to_datetime(first_date)\n",
    "            include = (df[event_start] >= date)\n",
    "        df = df[include]\n",
    "    \n",
    "    # exclude events after ...\n",
    "    if last_date:\n",
    "        df = df.dropna(subset=[last_date])\n",
    "\n",
    "        if last_date in df.columns:\n",
    "            include = (df[event_start] <= df[last_date])\n",
    "        else:\n",
    "            date = pd.to_datetime(last_date)\n",
    "            include = (df[event_start] <= df[last_date])\n",
    "        df = df[include]\n",
    "\n",
    "    # period represents the days from the first_date to be included\n",
    "    # cannot specify both period and last_date(?)\n",
    "    if period:\n",
    "        if first_date:\n",
    "            end_date = df[first_date] + pd.to_timedelta(period, unit='D')\n",
    "            include = (df[event_start] <= end_date)\n",
    "        else:\n",
    "            time_after = (df[event_start] - df.groupby(pid)[event_start].min()) / np.timedelta64(1, 'D')\n",
    "            include = (time_after <= period).values  # strange need this, tries to reindex if not\n",
    "        df = df[include]\n",
    "    \n",
    "    if isinstance(df, pd.Series):\n",
    "        df=df.to_frame()\n",
    "        cols = list(df.columns)\n",
    "        \n",
    "    # fix formatting of input\n",
    "    if fix:\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep, all_str=True)\n",
    "        codes = expand_code(codes, all_codes=all_codes)\n",
    "        cols = expand_columns(cols, df=df)\n",
    "        print('after stringified fix', codes)\n",
    "\n",
    "    only_codes=[]\n",
    "    for name, code in codes.items():\n",
    "        only_codes.extend(code)\n",
    "\n",
    "    # get the rows with the relevant columns\n",
    "    rows = get_rows(df=df, codes=only_codes, all_codes=all_codes, cols=cols, sep=sep)\n",
    "    subset = df[rows]  #  copy?\n",
    "    subset.index.name = 'pid_index'\n",
    "    subset = subset.sort_values(by=[pid, event_start]).set_index('pid')\n",
    "\n",
    "    # extract relevant codes and aggregate for each person\n",
    "    code_series = extract_codes(df=subset, codes=codes, cols=cols, sep=sep, \n",
    "                                new_sep='', merge=True, out='text')\n",
    "    \n",
    "    #    if isinstance(code_series, pd.DataFrame):\n",
    "    #        code_series = pd.Series(code_series)\n",
    "    string_df = code_series.groupby(level=0).apply(lambda codes: codes.str.cat(sep=time_sep))\n",
    "\n",
    "    # eliminate repeats in string\n",
    "    if not keep_repeats:\n",
    "        string_df = string_df.str.replace(r'([a-z])\\1+', r'\\1')\n",
    "\n",
    "    if only_unique:\n",
    "        def uniqify(text):\n",
    "            while re.search(r'([a-z])(.*)\\1', text):\n",
    "                text = re.sub(r'([a-z])(.*)\\1', r'\\1\\2', text)\n",
    "            return text\n",
    "\n",
    "        string_df = string_df.apply(uniqify)\n",
    "    return string_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def del_repeats(str_series):\n",
    "    \"\"\"\n",
    "    deletes consecutively repeated characters from the strings in a series\n",
    "\n",
    "    \"\"\"\n",
    "    no_repeats = str_series.str.replace(r'([a-z])\\1+', r'\\1')\n",
    "    return no_repeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## del singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def del_singles(text):\n",
    "    \"\"\"\n",
    "    Deletes single characters from string\n",
    "    todo: how to deal with first and last position ... delete it too?\n",
    "\n",
    "    \"\"\"\n",
    "    # text with only one character are by definition singles\n",
    "    if len(text) < 2:\n",
    "        no_singles = ''\n",
    "    else:\n",
    "        no_singles = \"\".join([letter for n, letter in enumerate(text[1:-1], start=1) if\n",
    "                              ((text[n - 1] == letter) or (text[n + 1] == letter))])\n",
    "        # long textx may not have any singles, so check before continue\n",
    "        if len(no_singles) < 1:\n",
    "            no_singles = ''\n",
    "        else:\n",
    "            if text[0] == no_singles[0]:\n",
    "                no_singles = text[0] + no_singles\n",
    "            if text[-1] == no_singles[-1]:\n",
    "                no_singles = no_singles + text[-1]\n",
    "\n",
    "    return no_singles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stringify time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stringify_time(df,\n",
    "                   codes=None,\n",
    "                   cols=None,\n",
    "                   pid='pid',\n",
    "                   sep=None,\n",
    "                   step=90,\n",
    "\n",
    "                   event_start='date',  # use start end\n",
    "                   nfirst=None,  # ncodes\n",
    "                   \n",
    "                   all_codes=None,\n",
    "                   first_date=None,\n",
    "                   # use just first, last, censored. Accept integers to indicate period/days relative to the start date\n",
    "                   last_date=None,\n",
    "                   censored_date=None,\n",
    "\n",
    "                   time_sep='|',\n",
    "                   no_event=' ',\n",
    "                   collision='*',\n",
    "\n",
    "                   merge=True,\n",
    "                   info=None):\n",
    "    \"\"\"\n",
    "    Creates a string for each individual describing events at position in time\n",
    "\n",
    "    Args:\n",
    "        df: dataframe\n",
    "        codes: codes to be used to mark an event\n",
    "        cols: columns with the event codes\n",
    "        pid: column with the personal identification number\n",
    "        event_start: column containing the date for the event\n",
    "        sep: the seperator used between events if a column has multiple events in a cell\n",
    "        keep_repeats: identical events after each other are reduced to one (if true)\n",
    "        only_unique: deletes all events that have occurred previously for the individual (if true)\n",
    "\n",
    "    Returns:\n",
    "        series with a string that describes the events for each individual\n",
    "\n",
    "    Example:\n",
    "        codes={'i': '4AB02', 'a':'4AB04'}\n",
    "        codes={'i': ['4AB02','L04AB02'], 'a': ['4AB04', 'L04AB04'], 'e':['4AB01']}\n",
    "\n",
    "\n",
    "        df['diagnosis_date']=df[df.icdmain.fillna('').str.contains('K50|K51')].groupby('pid')['start_date'].min()\n",
    "\n",
    "    a=stringify_time(df=mdf,  codes=codes, cols='codes', pid='pid', event_start='date',\n",
    "    first_date='first_ibd', step=90, sep=',', no_event=' ', time_sep=' ')\n",
    "\n",
    "\n",
    "    background\n",
    "        to identify treatment patters, first stringify each treatment,\n",
    "        then aggregate the different treatments to one string\n",
    "        each \"cell\" in the string (separated by sep) represent one time unit\n",
    "        the time unit can be further aggregated to reduce the level of detail\n",
    "\n",
    "    example output (one such row for each person)\n",
    "        a---s, a---, ai-s, a---, ----\n",
    "\n",
    "        Interpretation: A person with event a and s in first time perod, then a only in second,\n",
    "        the a, i and s in the third, a only in fourth and no events in the last\n",
    "\n",
    "    purpose\n",
    "        examine typical treatment patterns and correlations\n",
    "        use regex or other string operations on this to get statistcs\n",
    "        (time on first line of treatment, number of switches, stops)\n",
    "    \"\"\"\n",
    "\n",
    "    # drop rows with missing observations in required variables\n",
    "    df = df.dropna(subset=[pid, event_start])\n",
    "\n",
    "    # find default min and max dates to be used if not user specified\n",
    "    min_date = df[event_start].min()\n",
    "    max_date = df[event_start].max()\n",
    "\n",
    "    # drop rows outside time period of interest\n",
    "    if first_date:\n",
    "        if first_date in df.columns:\n",
    "            df = df[df[event_start] >= df[first_date]]\n",
    "        else:\n",
    "            min_date = pd.to_datetime(first_date)\n",
    "            df = df[df[event_start] >= min_date]\n",
    "\n",
    "    if last_date:\n",
    "        if last_date in df.columns:\n",
    "            df = df[df[event_start] >= df[last_date]]\n",
    "        else:\n",
    "            max_date = pd.to_datetime(last_date)\n",
    "            df = df[df[event_start] <= max_date]\n",
    "\n",
    "    # note an individual min date cannot be before overall specified min date\n",
    "    # should raise error if user tries this\n",
    "    # same with max: individual cannot be larger than overall\n",
    "\n",
    "    max_length_days = (max_date - min_date).days\n",
    "    max_length_steps = int(max_length_days / step)\n",
    "\n",
    "    # # if codes or nfirst are not specified, use the five most common codes\n",
    "    # if not codes:\n",
    "    #     cols = expand_columns(_listify(cols))\n",
    "    #     if not nfirst: nfirst = 5\n",
    "    #     codes = count_codes(df=df, cols=cols, sep=sep).sort_values(ascending=False)[:nfirst]\n",
    "\n",
    "    # fix formatting of input (make list out of a string input and so on)\n",
    "    \n",
    "    cols=expand_columns(cols, all_columns=list(df.columns))\n",
    "    if not all_codes:\n",
    "        all_codes = unique(df=df, cols=cols, sep=sep)\n",
    "    codes = expand_code(codes, all_codes=all_codes, info=info)\n",
    "    \n",
    "    only_codes = []\n",
    "    print('after stringified fix', codes)\n",
    "\n",
    "    only_codes=[]\n",
    "    for name, code in codes.items():\n",
    "        only_codes.extend(code)\n",
    "    \n",
    "    # get the rows that contain the relevant codes\n",
    "    rows = get_rows(df=df, codes=only_codes, cols=cols, sep=sep, all_codes=all_codes, fix=False)\n",
    "    subset = df[rows].copy()  # maybe use .copy to avoid warnings?\n",
    "    subset.index.name = 'pid_index'\n",
    "\n",
    "    # find position of each event (number of steps from overall min_date)\n",
    "    subset['position'] = (subset[event_start] - min_date).dt.days.div(step).astype(int)\n",
    "\n",
    "    subset = subset.sort_values(by=[pid, 'position']).set_index([pid, 'position'])\n",
    "\n",
    "    # create series with only the relevant codes for each person and position\n",
    "    code_series = extract_codes(df=subset,\n",
    "                                codes=codes,\n",
    "                                cols=cols,\n",
    "                                sep=sep,\n",
    "                                new_sep=',',\n",
    "                                merge=True,\n",
    "                                out='text',\n",
    "                                fix=False)\n",
    "\n",
    "    # base further aggregation on the new extracted series with its col and codes\n",
    "    col = code_series.name\n",
    "    codes = code_series.name.split(', ')\n",
    "\n",
    "    # drop duplicates (same type of even in same period for same individual)\n",
    "    code_series = code_series.reset_index().drop_duplicates().set_index(pid, drop=False)\n",
    "    code_series.index.name = 'pid_index'\n",
    "\n",
    "    ## make dict with string start end end positions for each individual\n",
    "    # explanation:\n",
    "    # the string is first made marking events in positions using calendar time\n",
    "    # but often we want the end result to be strings that start at specified\n",
    "    # individual dates, and not the same calendar date for all\n",
    "    # for instance it is often useful to start the string at the date the\n",
    "    # person receives a diagnosis\n",
    "    # same with end of string: strings may end when a patient dies\n",
    "    # user can specify start and end dates by pointing to columns with dates\n",
    "    # or they may specify an overall start and end date\n",
    "    # if individual dates are specified, the long string based on calendar\n",
    "    # time is sliced to include only the relevant events\n",
    "\n",
    "    if first_date:\n",
    "        # if a column is specified\n",
    "        if first_date in subset.columns:\n",
    "            start_date = subset.groupby(pid)[first_date].first().dropna().to_dict()\n",
    "        # if a single overall date is specified\n",
    "        else:\n",
    "            date = pd.to_datetime(first_date)\n",
    "            start_date = {pid: date for pid in subset[pid].unique()}\n",
    "        # convert start date to start position in string\n",
    "        start_position = {pid: int((date - min_date).days / step)\n",
    "                          for pid, date in start_date.items()}\n",
    "\n",
    "    if last_date:\n",
    "        if last_date in subset:\n",
    "            end_date = subset.groupby(pid)[last_date].first().dropna().to_dict()\n",
    "        else:\n",
    "            date = pd.to_datetime(last_date)\n",
    "            end_date = {pid: date for pid in subset[pid].unique()}\n",
    "        # convert date to position in string\n",
    "        end_position = {pid: (date - min_date).dt.days.div(step).astype(int)\n",
    "                        for pid, date in end_date.items()}\n",
    "\n",
    "    # takes dataframe for an individual and makes a string with the events\n",
    "    def make_string(events):\n",
    "        # get pid of individual (required to find correct start and end point)\n",
    "        person = events[pid].iloc[0]\n",
    "\n",
    "        # make a list of maximal length with no events\n",
    "        event_list = [no_event] * (max_length_steps + 1)\n",
    "\n",
    "        # loop over all events the individual has and put code in correct pos.\n",
    "        for pos in events['position'].values:\n",
    "            event_list[pos] = code\n",
    "\n",
    "        event_string = \"\".join(event_list)\n",
    "\n",
    "        # slice to correct start and end of string (if specified)\n",
    "        if first_date:\n",
    "            event_string = event_string[start_position[person]:]\n",
    "        if last_date:\n",
    "            event_string = event_string[:-(max_length_steps - end_position[person])]\n",
    "        return event_string\n",
    "\n",
    "    # new dataframe to store each string for each individual for each code\n",
    "    string_df = pd.DataFrame(index=code_series[pid].unique())\n",
    "\n",
    "    # loop over each code, create aggregate string for each individual, store in df\n",
    "    for code in codes:\n",
    "        code_df = code_series[code_series[col].isin([code])]\n",
    "        stringified = code_df.groupby(pid, sort=False).apply(make_string)\n",
    "        string_df[code] = stringified\n",
    "\n",
    "    if merge:\n",
    "        string_df = interleave_strings(string_df, no_event=no_event, time_sep=time_sep)\n",
    "    return string_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.clean import nbdev_clean_nbs\n",
    "from nbdev.clean import clean_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbdev_clean_nbs('patt*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nb('pattern_finder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.sync import script2notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "234.3px",
    "width": "251.5px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
